{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf44257",
   "metadata": {},
   "source": [
    "## NLP06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d4845",
   "metadata": {},
   "source": [
    "### 노드19\n",
    "- vocabulary size 변경\n",
    "- 실험 조건은(TF-IDF행렬 기준으로, 노드18은 num_words=10,000)\n",
    "  - 10,000 단어\n",
    "  - 5,000 단어\n",
    "  - 모든 단어 쓴다면?\n",
    "- 참고사항\n",
    "  - lightGBM은 이번 경우에는 성능 매우 낮음!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b405bd",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "- 단어장 개수가 커질수록 성능 높아진 모델\n",
    "  - LogisticRegression, SVM\n",
    "- 단어장 개수가 커질수록 성능 낮아진 모델\n",
    "  - RandomForest, KNN, NaiveBayes\n",
    "- LogisticRegression이 성능이 좋지만, XGBoost도 성능이 비슷하고 무엇보다 단어장 크기에 큰 영향 안 받음\n",
    "  - 딥러닝 모델과는 XGBoost를 비교대상으로 삼았음\n",
    "- ML/DL 비교 관련\n",
    "  - Dense net(MLP)는 성능이 xgboost 대비 떨어짐(batch 32->16으로 줄이고 epochs 10->20 했음에도)\n",
    "  - 단 Dense net(MLP)은 문장별 평균 벡터로 입력층을 변화시키면 성능이 개선됨\n",
    "  - RNN의 경우, MLP대비 성능이 우수했으나 XGBoost나 Logistic 대비 성능이 좋지 않았음(num_words=10000기준)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4154e6",
   "metadata": {},
   "source": [
    "### 실험 결과 요약\n",
    "1. 단어장 개수를 바꾸면서(10000, 5000, Nan) 8개의 ML모델을 사용해보고\n",
    "accuacry와 f1-score를 비교(벡터화는 tf-idf로 통일)\n",
    "\n",
    "\n",
    "#### 단어장 개수별 ML 모델 성능 비교 (Accuracy / F1-score)\n",
    "\n",
    "    \n",
    "| Vocabulary Size | Model             | Accuracy | F1-Score | 시간(초)     |\n",
    "|------------------|------------------|----------|----------| -------------|\n",
    "| 10000            | LogisticRegression |  0.8108  |   0.8057 |   747초    |\n",
    "|                  | SVM                |  0.7850 |    0.7818 |   136초   |\n",
    "|                  | RandomForest       |  0.6741  |   0.6429 |     2초    |\n",
    "|                  | XGBoost            |  0.7907    | 0.7841 | 217초      |\n",
    "|                  | NaiveBayes         |  0.6567   |  0.5764 | 1초 미만   |\n",
    "|                  | KNN                |  0.7894 |    0.7891 | 1초 미만   |\n",
    "|                  | LightGBM           |  0.0614   |  0.0462 | 55초       |\n",
    "|                  | DecisionTree       | 0.6923    |  0.6895  |  8초       |\n",
    "| 5000             | LogisticRegression | 0.8037    |  0.798   |  502초   |\n",
    "|                  | SVM                | 0.7685   |   0.7647 |   149초    |\n",
    "|                  | RandomForest       | 0.7012   |   0.6770 |     2초    |\n",
    "|                  | XGBoost            | 0.7947   |   0.7847 |   206초    |\n",
    "|                  | NaiveBayes         | 0.6732   |   0.6013 |   1초미만  |\n",
    "|                  | KNN                | 0.7823   |   0.7709 |    1초미만  |\n",
    "|                  | LightGBM           | 0.2364   |   0.2919 |    51초    |\n",
    "|                  | DecisionTree       | 0.6981   |   0.6933 |     7초  |\n",
    "| NaN (All words)  | LogisticRegression | 0.8166   |   0.8114 |   915초    |\n",
    "|                  | SVM                | 0.7916   |   0.7873 |   126초    |\n",
    "|                  | RandomForest       | 0.6545   |   0.6226 |     3초    |\n",
    "|                  | XGBoost            | 0.7947   |   0.7883 |   233초    |\n",
    "|                  | NaiveBayes         | 0.5997   |   0.5046 |  1초 미만  |\n",
    "|                  | KNN                | 0.7720   |   0.7639 |  1초 미만  |\n",
    "|                  | LightGBM           | 0.3353   |   0.3037 |    49초    |\n",
    "|                  | DecisionTree       | 0.7057   |   0.7021 |     8초    |\n",
    "    \n",
    "\n",
    "2. 딥러닝과 머신런닝의 차이 비교하기\n",
    "- 벡터화 방법을 바꿔보며(DTM, W2V) 머신러닝 모델1개(성능 높은 모델), 딥러닝 모델 2개(Dense, RNN)를 비교   \n",
    "  평가지표 = accuacry, f1-score\n",
    "\n",
    "#### 벡터화 방법별 ML/DL 모델 성능 비교 (Accuracy / F1-score)\n",
    "\n",
    "| Vectorization | Model           | Accuracy | F1-Score  | 시간(초)|\n",
    "|---------------|------------------|----------|----------|---------|\n",
    "| Word2Vec      | XGBoost          |  0.7907  | 0.7841   |  217초  |\n",
    "|               | Dense NN         |  0.6665  | 0.6363   |   50초  |\n",
    "|               | Dense NN(평균벡터)| 0.7569  | 0.7396   |   37초  |\n",
    "|               | RNN              |  0.7841  | 0.7751   |   68초  |\n",
    "|               | RNN(변경)        |  0.7787  | 0.7622   |   68초  |\n",
    "\n",
    "- RNN의 경우, BatchNormalization, ReduceLROnPlateau 적용했으나 별 차이 없었음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0b831",
   "metadata": {},
   "source": [
    "#### 19-01 머신러닝\n",
    "- vector화를 위해 전처리된 데이터를 text형태로 원복(노드18과 동일)\n",
    "- 10,000단어 기준"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9627a1a",
   "metadata": {},
   "source": [
    "##### 데이터전처리 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182d7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f8d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc689bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수:8982\n",
      "테스트 샘플의 수:2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수:{}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수:{}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6de49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221c0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0698d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e613ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded_test = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded_test.append(t)\n",
    "\n",
    "x_test = decoded_test\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede4e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 DTM, TF-idf 방법\n",
    "dtmvector = CountVectorizer()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm= dtmvector.transform(x_test)\n",
    "\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669f1b0",
   "metadata": {},
   "source": [
    "##### 로지스틱\n",
    "- 로지스틱 대신 SGDClassifier쓰면 훨씬 빠름\n",
    "- sklearn.linear_model import SGDClassifier\n",
    "- loss = 'log' 또는 'log_loss' (sklearn버전따라 다르니 주의!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ee273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:915.2초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "st = time.time()\n",
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "lr.fit(x_train_tfidf, y_train)\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f004f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8165627782724845\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4e27aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy : 0.8166\n",
      " F1-score : 0.8114\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae7701",
   "metadata": {},
   "source": [
    "###### 참고 SGD\n",
    "- 살짝 성능은 떨어지지만 훨씬 결과 빠르게 나오는 것 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4135dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:3.63초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "st = time.time()\n",
    "sgd_lr = SGDClassifier(loss='log', max_iter=3000, tol=1e-3)  # log_loss = 로지스틱 손실\n",
    "sgd_lr.fit(x_train_tfidf, y_train)\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07e9d54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7943009795191451\n"
     ]
    }
   ],
   "source": [
    "predicted = sgd_lr.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db15f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy : 0.7943\n",
      " F1-score : 0.7707\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d88a3",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "104d3d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:125.87초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "lsvc.fit(x_train_tfidf, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86e264a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7916295636687445\n"
     ]
    }
   ],
   "source": [
    "predicted = lsvc.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb581e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy : 0.7916\n",
      " F1-score : 0.7873\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b8baed",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37929cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:2.46초\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "rf_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9756d00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6544968833481746\n"
     ]
    }
   ],
   "source": [
    "predicted = rf_clf.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3280c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy : 0.6545\n",
      " F1-score : 0.6226\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a78b1",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f36d7183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:232.37초\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=5, eval_metric='mlogloss')\n",
    "xgb_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "516c501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.794746215494212\n"
     ]
    }
   ],
   "source": [
    "predicted = xgb_clf.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5813862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy : 0.7947\n",
      " F1-score : 0.7883\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98f051",
   "metadata": {},
   "source": [
    "##### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf9f05c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:0.06초\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bf4a1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.5997328584149599\n"
     ]
    }
   ],
   "source": [
    "predicted = nb_clf.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10acc24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy : 0.5997\n",
      " F1-score : 0.5046\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5431dee3",
   "metadata": {},
   "source": [
    "##### KNN\n",
    "- n=5로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ab519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:0.0초\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "print(f'소요시간:{round(ed-st,2)}초')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96846bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7720391807658059\n"
     ]
    }
   ],
   "source": [
    "predicted = knn_clf.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a03a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy : 0.7720\n",
      " F1-score : 0.7639\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f75d427",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d62e0218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:49.79초\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "# lightgbm은 dense하게 변경 필요\n",
    "\n",
    "x_train_dense = x_train_tfidf.toarray()\n",
    "x_test_dense = x_test_tfidf.toarray()\n",
    "\n",
    "lgbm_clf = LGBMClassifier(objective='multiclass', num_class=46, n_estimators=200, learning_rate=0.1, max_depth=6)\n",
    "lgbm_clf.fit(x_train_dense, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6d7df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.3352626892252894\n",
      " Accuracy : 0.3353\n",
      " F1-score : 0.3037\n"
     ]
    }
   ],
   "source": [
    "predicted = lgbm_clf.predict(x_test_dense) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "\n",
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f69d6e3",
   "metadata": {},
   "source": [
    "##### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce5d4b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:8.01초\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3680a422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7056990204808549\n",
      " Accuracy : 0.7057\n",
      " F1-score : 0.7021\n"
     ]
    }
   ],
   "source": [
    "predicted = dt_clf.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "\n",
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816e252",
   "metadata": {},
   "source": [
    "#### 19-02 ML/DL 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f3cb9",
   "metadata": {},
   "source": [
    "##### 데이터준비(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac7d7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_rain), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0674df30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수:8982\n",
      "테스트 샘플의 수:2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수:{}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수:{}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d18dd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddad0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20c45ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "facbd500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded_test = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded_test.append(t)\n",
    "\n",
    "x_test = decoded_test\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ba23435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 DTM, TF-idf 방법\n",
    "dtmvector = CountVectorizer()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm= dtmvector.transform(x_test)\n",
    "\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5dedd4",
   "metadata": {},
   "source": [
    "##### 데이터준비(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "995023f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "# 벡터화 W2V방법\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 우선 문장을 토큰화 시킵시다 띄어쓰기 기반으로 해볼게요! -> # 위에서 DTM만들때는 왜 안해줬냐! -> CountVectorizer에서 띄어쓰기 기반 토큰화가 내장되있음\n",
    "x_train_tokenized = [sentence.split() for sentence in x_train]\n",
    "x_test_tokenized = [sentence.split() for sentence in x_test]\n",
    "\n",
    "# vector사이즈를 늘리거나 줄여보세요 아마 512 가장많이쓰이는 방식\n",
    "model = Word2Vec(sentences = x_train_tokenized, vector_size = 256, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(\"모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "199df61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Word2Vec 모델\n",
    "w2v_model = model\n",
    "\n",
    "# 각 문장을 벡터화 시키는 코드\n",
    "def vectorize_sentence(sentence, model, max_len):\n",
    "    vecs = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            vecs.append(model.wv[word])\n",
    "        else:\n",
    "            vecs.append(np.zeros(model.vector_size))\n",
    "    # Padding\n",
    "    if len(vecs) < max_len:\n",
    "        vecs += [np.zeros(model.vector_size)] * (max_len - len(vecs))\n",
    "    else:\n",
    "        vecs = vecs[:max_len]\n",
    "    return np.array(vecs)\n",
    "\n",
    "\n",
    "# 최대 문장길이를 잘 잡아주세요\n",
    "x_train_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_train_tokenized])\n",
    "x_test_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_test_tokenized])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e30962",
   "metadata": {},
   "source": [
    "##### XG-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb961b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간:217.14초\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=5, eval_metric='mlogloss')\n",
    "xgb_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12d965c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7907390917186109\n",
      " Accuracy : 0.7907\n",
      " F1-score : 0.7841\n"
     ]
    }
   ],
   "source": [
    "predicted = xgb_clf.predict(x_test_tfidf) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "# 평가 지표\n",
    "# predicted(y_pred)\n",
    "acc = accuracy_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print(f\" Accuracy : {acc:.4f}\")\n",
    "print(f\" F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab2ca4",
   "metadata": {},
   "source": [
    "##### MLP\n",
    "- dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf4d214d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               13107712  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 13,179,310\n",
      "Trainable params: 13,179,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "dense_model = Sequential([\n",
    "    Flatten(input_shape=(100, 256)),  # (seq_len, embedding_dim)\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')   # 클래스 수에 맞게 조정 46개로 맞춰주세요!\n",
    "])\n",
    "\n",
    "dense_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c434103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 1.9629 - accuracy: 0.5713 - val_loss: 1.4929 - val_accuracy: 0.6656\n",
      "Epoch 2/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 1.4824 - accuracy: 0.6598 - val_loss: 1.4102 - val_accuracy: 0.6845\n",
      "Epoch 3/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 1.2535 - accuracy: 0.7073 - val_loss: 1.4182 - val_accuracy: 0.6817\n",
      "Epoch 4/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 1.0726 - accuracy: 0.7502 - val_loss: 1.4123 - val_accuracy: 0.6889\n",
      "Epoch 5/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.9428 - accuracy: 0.7748 - val_loss: 1.4393 - val_accuracy: 0.6956\n",
      "Epoch 6/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.8675 - accuracy: 0.7884 - val_loss: 1.5306 - val_accuracy: 0.6822\n",
      "Epoch 7/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.8002 - accuracy: 0.8084 - val_loss: 1.5775 - val_accuracy: 0.6817\n",
      "Epoch 8/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7967 - accuracy: 0.8118 - val_loss: 1.5537 - val_accuracy: 0.6917\n",
      "Epoch 9/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7092 - accuracy: 0.8217 - val_loss: 1.6494 - val_accuracy: 0.6845\n",
      "Epoch 10/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7041 - accuracy: 0.8308 - val_loss: 1.7625 - val_accuracy: 0.6761\n",
      "Epoch 11/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7107 - accuracy: 0.8319 - val_loss: 1.6351 - val_accuracy: 0.6644\n",
      "Epoch 12/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6542 - accuracy: 0.8438 - val_loss: 1.7732 - val_accuracy: 0.6834\n",
      "Epoch 13/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6243 - accuracy: 0.8455 - val_loss: 1.8905 - val_accuracy: 0.6789\n",
      "Epoch 14/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6236 - accuracy: 0.8515 - val_loss: 1.9183 - val_accuracy: 0.6800\n",
      "Epoch 15/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5988 - accuracy: 0.8565 - val_loss: 1.9346 - val_accuracy: 0.6778\n",
      "Epoch 16/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5949 - accuracy: 0.8554 - val_loss: 2.0221 - val_accuracy: 0.6778\n",
      "Epoch 17/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5728 - accuracy: 0.8597 - val_loss: 2.0624 - val_accuracy: 0.6784\n",
      "Epoch 18/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5963 - accuracy: 0.8568 - val_loss: 2.2400 - val_accuracy: 0.6711\n",
      "Epoch 19/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5656 - accuracy: 0.8672 - val_loss: 2.2177 - val_accuracy: 0.6778\n",
      "Epoch 20/20\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5687 - accuracy: 0.8686 - val_loss: 2.1357 - val_accuracy: 0.6706\n",
      "소요시간:50.8초\n"
     ]
    }
   ],
   "source": [
    "# 시간이 좀 걸립니다! 한 20분정도.. (초기값 epochs =10 ,epochs = 20으로 늘리면 몇 분?)\n",
    "import time\n",
    "st = time.time()\n",
    "dense_model.fit(x_train_w2v, y_train, epochs=20, batch_size=16, validation_split=0.2)\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2a29cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.6665\n",
      " F1-score: 0.6363\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = dense_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\" Accuracy: {acc:.4f}\")\n",
    "print(f\" F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf15acf",
   "metadata": {},
   "source": [
    "##### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "701782c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 208,366\n",
      "Trainable params: 208,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rnn 시계열 특징 데이터 특화 모델\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    LSTM(128, input_shape=(100, 256)),  # (seq_len, embedding_dim)\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')   # 클래스 수에 맞게 조정 46개로 맞춰주세요~\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51a1a412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.0408 - accuracy: 0.7461 - val_loss: 1.1124 - val_accuracy: 0.7396\n",
      "Epoch 2/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 1.0134 - accuracy: 0.7520 - val_loss: 1.0803 - val_accuracy: 0.7574\n",
      "Epoch 3/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.9641 - accuracy: 0.7665 - val_loss: 1.0271 - val_accuracy: 0.7674\n",
      "Epoch 4/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.9044 - accuracy: 0.7770 - val_loss: 0.9906 - val_accuracy: 0.7741\n",
      "Epoch 5/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.8366 - accuracy: 0.7974 - val_loss: 0.9985 - val_accuracy: 0.7741\n",
      "Epoch 6/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.8117 - accuracy: 0.7996 - val_loss: 0.9980 - val_accuracy: 0.7657\n",
      "Epoch 7/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.7637 - accuracy: 0.8106 - val_loss: 0.9982 - val_accuracy: 0.7830\n",
      "Epoch 8/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.7382 - accuracy: 0.8182 - val_loss: 0.9798 - val_accuracy: 0.7752\n",
      "Epoch 9/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.7075 - accuracy: 0.8196 - val_loss: 0.9912 - val_accuracy: 0.7763\n",
      "Epoch 10/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6841 - accuracy: 0.8278 - val_loss: 1.0085 - val_accuracy: 0.7741\n",
      "Epoch 11/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6764 - accuracy: 0.8287 - val_loss: 1.0445 - val_accuracy: 0.7780\n",
      "Epoch 12/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6137 - accuracy: 0.8436 - val_loss: 1.0057 - val_accuracy: 0.7763\n",
      "Epoch 13/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6010 - accuracy: 0.8465 - val_loss: 1.0448 - val_accuracy: 0.7769\n",
      "Epoch 14/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5737 - accuracy: 0.8580 - val_loss: 1.0801 - val_accuracy: 0.7791\n",
      "Epoch 15/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5702 - accuracy: 0.8551 - val_loss: 1.0590 - val_accuracy: 0.7796\n",
      "Epoch 16/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5393 - accuracy: 0.8615 - val_loss: 1.0717 - val_accuracy: 0.7846\n",
      "Epoch 17/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5201 - accuracy: 0.8668 - val_loss: 1.0870 - val_accuracy: 0.7846\n",
      "Epoch 18/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5031 - accuracy: 0.8717 - val_loss: 1.0864 - val_accuracy: 0.7874\n",
      "Epoch 19/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.4927 - accuracy: 0.8703 - val_loss: 1.1310 - val_accuracy: 0.7713\n",
      "Epoch 20/20\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.4839 - accuracy: 0.8754 - val_loss: 1.1421 - val_accuracy: 0.7846\n",
      "소요시간:68.05초\n"
     ]
    }
   ],
   "source": [
    "# 시간이 좀 걸립니다! 한 20분정도\n",
    "import time\n",
    "st = time.time()\n",
    "rnn_model.fit(x_train_w2v, y_train, epochs=20, batch_size=16, validation_split=0.2)\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간:{round(ed-st,2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bce2d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7841\n",
      " F1-score: 0.7752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_proba = rnn_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\" Accuracy: {acc:.4f}\")\n",
    "print(f\" F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a6a02",
   "metadata": {},
   "source": [
    "##### MLP 개선\n",
    "- 입력 데이터 변환: 문장별 평균 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7df928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 203,182\n",
      "Trainable params: 203,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 1.5759 - accuracy: 0.6430 - val_loss: 1.2251 - val_accuracy: 0.7123\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 1.2317 - accuracy: 0.7059 - val_loss: 1.1223 - val_accuracy: 0.7351\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 1.1591 - accuracy: 0.7247 - val_loss: 1.1168 - val_accuracy: 0.7251\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 1.1082 - accuracy: 0.7307 - val_loss: 1.0502 - val_accuracy: 0.7485\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 1.0748 - accuracy: 0.7374 - val_loss: 1.0453 - val_accuracy: 0.7446\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 1.0380 - accuracy: 0.7466 - val_loss: 1.0232 - val_accuracy: 0.7546\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 1.0199 - accuracy: 0.7499 - val_loss: 1.0150 - val_accuracy: 0.7635\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.9954 - accuracy: 0.7521 - val_loss: 1.0269 - val_accuracy: 0.7568\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.9692 - accuracy: 0.7587 - val_loss: 1.0078 - val_accuracy: 0.7624\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.9518 - accuracy: 0.7623 - val_loss: 0.9864 - val_accuracy: 0.7646\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.9378 - accuracy: 0.7649 - val_loss: 0.9855 - val_accuracy: 0.7596\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.9172 - accuracy: 0.7701 - val_loss: 0.9840 - val_accuracy: 0.7663\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.9070 - accuracy: 0.7698 - val_loss: 0.9995 - val_accuracy: 0.7679\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8864 - accuracy: 0.7720 - val_loss: 0.9852 - val_accuracy: 0.7657\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8815 - accuracy: 0.7741 - val_loss: 0.9896 - val_accuracy: 0.7674\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8569 - accuracy: 0.7759 - val_loss: 0.9890 - val_accuracy: 0.7674\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8418 - accuracy: 0.7786 - val_loss: 0.9868 - val_accuracy: 0.7679\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8280 - accuracy: 0.7808 - val_loss: 1.0089 - val_accuracy: 0.7724\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8211 - accuracy: 0.7781 - val_loss: 1.0159 - val_accuracy: 0.7624\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8164 - accuracy: 0.7850 - val_loss: 0.9737 - val_accuracy: 0.7769\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.8045 - accuracy: 0.7901 - val_loss: 0.9972 - val_accuracy: 0.7741\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7936 - accuracy: 0.7954 - val_loss: 0.9860 - val_accuracy: 0.7735\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7726 - accuracy: 0.7936 - val_loss: 1.0175 - val_accuracy: 0.7691\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7634 - accuracy: 0.7946 - val_loss: 0.9607 - val_accuracy: 0.7785\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7640 - accuracy: 0.7981 - val_loss: 0.9936 - val_accuracy: 0.7752\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7350 - accuracy: 0.7979 - val_loss: 0.9863 - val_accuracy: 0.7757\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7166 - accuracy: 0.8054 - val_loss: 0.9824 - val_accuracy: 0.7730\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7186 - accuracy: 0.8046 - val_loss: 0.9958 - val_accuracy: 0.7763\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7204 - accuracy: 0.8046 - val_loss: 0.9987 - val_accuracy: 0.7757\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6963 - accuracy: 0.8024 - val_loss: 1.0116 - val_accuracy: 0.7780\n",
      "소요시간: 37.43초\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import time\n",
    "\n",
    "# 1. 입력 데이터 변환: 문장별 평균 벡터\n",
    "x_train_mean = x_train_w2v.mean(axis=1)  # shape: (n_samples, 256)\n",
    "x_test_mean = x_test_w2v.mean(axis=1)    # shape: (n_samples, 256)\n",
    "\n",
    "# 2. 모델 정의\n",
    "dense_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(256,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# 3. 컴파일\n",
    "dense_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "dense_model.summary()\n",
    "\n",
    "# 4. 학습\n",
    "st = time.time()\n",
    "dense_model.fit(x_train_mean, y_train, epochs=30, batch_size=16, validation_split=0.2)\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간: {round(ed - st, 2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67f7ccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7569\n",
      " F1-score: 0.7396\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = dense_model.predict(x_test_mean)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\" Accuracy: {acc:.4f}\")\n",
    "print(f\" F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d75553",
   "metadata": {},
   "source": [
    "##### RNN 개선\n",
    "- BatchNormalization : LSTM 후 hidden activation 안정화 → 더 빠른 수렴\n",
    "- EarlyStopping : validation 성능이 plateau에 도달하면 자동 종료\n",
    "- ReduceLROnPlateau : 정체 구간에서 learning rate를 줄여 local minima 탈출 유도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa511aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 209,134\n",
      "Trainable params: 208,750\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 8s 11ms/step - loss: 2.4407 - accuracy: 0.4796 - val_loss: 2.0341 - val_accuracy: 0.4597\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.9751 - accuracy: 0.5349 - val_loss: 1.7512 - val_accuracy: 0.5576\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.6282 - accuracy: 0.6028 - val_loss: 1.3917 - val_accuracy: 0.6689\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.3789 - accuracy: 0.6697 - val_loss: 1.2022 - val_accuracy: 0.7123\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.2640 - accuracy: 0.6988 - val_loss: 1.1307 - val_accuracy: 0.7385\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.1665 - accuracy: 0.7212 - val_loss: 1.0910 - val_accuracy: 0.7524\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.1046 - accuracy: 0.7311 - val_loss: 1.0253 - val_accuracy: 0.7602\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 1.0315 - accuracy: 0.7474 - val_loss: 1.0171 - val_accuracy: 0.7663\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 0.9965 - accuracy: 0.7628 - val_loss: 0.9758 - val_accuracy: 0.7774\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 0.9578 - accuracy: 0.7660 - val_loss: 0.9540 - val_accuracy: 0.7796\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 0.8943 - accuracy: 0.7837 - val_loss: 0.9748 - val_accuracy: 0.7752\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 0.8708 - accuracy: 0.7869 - val_loss: 0.9673 - val_accuracy: 0.7846\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 0.7931 - accuracy: 0.8132 - val_loss: 0.9120 - val_accuracy: 0.7896\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 0.7488 - accuracy: 0.8186 - val_loss: 0.9339 - val_accuracy: 0.7913\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.7174 - accuracy: 0.8227 - val_loss: 0.9293 - val_accuracy: 0.7869\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.6690 - accuracy: 0.8377 - val_loss: 0.9195 - val_accuracy: 0.7891\n",
      "소요시간: 68.36초\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import time\n",
    "\n",
    "# 모델 정의\n",
    "rnn_model = Sequential([\n",
    "    LSTM(128, input_shape=(100, 256)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')  # 클래스 수 = 46\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.summary()\n",
    "\n",
    "# 콜백 설정\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "\n",
    "# 학습\n",
    "st = time.time()\n",
    "rnn_model.fit(\n",
    "    x_train_w2v, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, lr_scheduler]\n",
    ")\n",
    "ed = time.time()\n",
    "\n",
    "print(f'소요시간: {round(ed - st, 2)}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d9394b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7787\n",
      " F1-score: 0.7622\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_proba = rnn_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\" Accuracy: {acc:.4f}\")\n",
    "print(f\" F1-score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
