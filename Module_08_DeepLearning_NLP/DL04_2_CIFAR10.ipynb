{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:16:26.900241Z","iopub.execute_input":"2025-06-11T17:16:26.900501Z","iopub.status.idle":"2025-06-11T17:16:29.361119Z","shell.execute_reply.started":"2025-06-11T17:16:26.900473Z","shell.execute_reply":"2025-06-11T17:16:29.359994Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## CIFAR-10 case\n- cifar-10 데이터로 MLP, CNN 차이 확인\n- CNN layer 직접 설계해보고, 전이학습(transfer learning, EfficientNetB0)도 해보기\n- Colab, LMS session 등의 문제로 kaggle-notebook 통해서 실험","metadata":{}},{"cell_type":"markdown","source":"### 01 MLP실험\n- MLP가 cifar-10같은 이미지 데이터에 한계 있음을 인지","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.datasets import cifar10\n\n(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n# 훈련 데이터셋에서 20%를 검증 데이터셋으로 분리\nx_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, \n                                                  test_size=0.2, \n                                                  random_state=42)\n                                                  \n# 훈련, 검증, 테스트 데이터와 레이블 종류가 몇개인지 출력합니다.\nprint(\"전체 학습 데이터: {} 레이블: {}\".format(x_train_full.shape, y_train_full.shape))\nprint(\"학습 데이터: {} 레이블: {}\".format(x_train.shape, y_train.shape))\nprint(\"검증 데이터: {} 레이블: {}\".format(x_val.shape, y_val.shape))\nprint(\"테스트 데이터: {} 레이블: {}\".format(x_test.shape, y_test.shape))\n\n# cifar10의 분류에 해당하는 'airplane', 'automobile', 'bird', 'cat', 'deer', \n# 'dog', 'frog', 'horse', 'ship', 'truck'를 class_name으로 정의합니다.\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck']\n\nx_train = x_train.reshape(-1, 32*32*3)\nx_val = x_val.reshape(-1, 32*32*3)\nx_test = x_test.reshape(-1, 32*32*3)\n\nprint(x_train.shape)\nprint(x_val.shape)\nprint(x_test.shape)\n\n# 훈련, 검증, 테스트 데이터를 255로 나누어 0~1 사이의 값으로 변환합니다.\nx_train = x_train / 255.\nx_val = x_val / 255.\nx_test = x_test / 255.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:21:01.931143Z","iopub.execute_input":"2025-06-11T17:21:01.931314Z","iopub.status.idle":"2025-06-11T17:21:28.877423Z","shell.execute_reply.started":"2025-06-11T17:21:01.931298Z","shell.execute_reply":"2025-06-11T17:21:28.876827Z"}},"outputs":[{"name":"stderr","text":"2025-06-11 17:21:07.166780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749662467.543545      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749662467.655157      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n전체 학습 데이터: (50000, 32, 32, 3) 레이블: (50000, 1)\n학습 데이터: (40000, 32, 32, 3) 레이블: (40000, 1)\n검증 데이터: (10000, 32, 32, 3) 레이블: (10000, 1)\n테스트 데이터: (10000, 32, 32, 3) 레이블: (10000, 1)\n(40000, 3072)\n(10000, 3072)\n(10000, 3072)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from tensorflow.keras import models, layers\n\n# 모델 구성 시작\nmodel = models.Sequential()\n# 입력층 (flatten된 이미지 데이터)\nmodel.add(layers.Input(shape=(3072,)))\n\n# 첫 번째 은닉층\nmodel.add(layers.Dense(2048, activation = 'relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\n\n# 두 번째 은닉층\nmodel.add(layers.Dense(1024, activation = 'relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\n\n# 세 번째 은닉층\nmodel.add(layers.Dense(512, activation = 'relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\n\n# 출력층 (CIFAR-10은 10개의 클래스)\nmodel.add(layers.Dense(10, activation='softmax'))\n\n# 모델 컴파일\nmodel.compile(optimizer='adam', # rmsprop에서 adam으로 변경\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:21:49.215217Z","iopub.execute_input":"2025-06-11T17:21:49.215491Z","iopub.status.idle":"2025-06-11T17:21:53.391952Z","shell.execute_reply.started":"2025-06-11T17:21:49.215470Z","shell.execute_reply":"2025-06-11T17:21:53.391272Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1749662511.519848      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1749662511.520495      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\n# 콜백 정의(ModelCheckPoint, EarlyStopping)\ncheck_point_cb = ModelCheckpoint(\n    filepath = 'cifar10_model.keras',\n    monitor = 'val_loss',\n    mode = 'min',\n    save_best_only = True,\n    verbose = 1\n)\n\nearly_stopping_cb = EarlyStopping(\n    monitor='val_loss',\n    patience=10,                          # 개선 없으면 중단\n    restore_best_weights=True,           # 가장 좋은 가중치 복원\n    verbose=1\n)\n\nhistory_pj3_3 = model.fit(x_train, y_train,\n                          epochs = 60,\n                          validation_data = (x_val, y_val),\n                          callbacks=[check_point_cb, early_stopping_cb])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:22:02.132413Z","iopub.execute_input":"2025-06-11T17:22:02.132940Z","iopub.status.idle":"2025-06-11T17:27:10.334493Z","shell.execute_reply.started":"2025-06-11T17:22:02.132915Z","shell.execute_reply":"2025-06-11T17:27:10.333910Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1749662527.202216     100 service.cc:148] XLA service 0x131e5150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1749662527.203739     100 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749662527.203760     100 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749662527.676810     100 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  36/1250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1237 - loss: 3.4868    ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749662530.544579     100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2343 - loss: 2.5067\nEpoch 1: val_loss improved from inf to 1.79651, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2343 - loss: 2.5062 - val_accuracy: 0.3595 - val_loss: 1.7965\nEpoch 2/60\n\u001b[1m1237/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3426 - loss: 1.8446\nEpoch 2: val_loss did not improve from 1.79651\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3426 - loss: 1.8445 - val_accuracy: 0.3232 - val_loss: 1.9378\nEpoch 3/60\n\u001b[1m1246/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3607 - loss: 1.7953\nEpoch 3: val_loss did not improve from 1.79651\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3607 - loss: 1.7952 - val_accuracy: 0.3507 - val_loss: 1.8012\nEpoch 4/60\n\u001b[1m1239/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3713 - loss: 1.7529\nEpoch 4: val_loss improved from 1.79651 to 1.71995, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3713 - loss: 1.7530 - val_accuracy: 0.3913 - val_loss: 1.7200\nEpoch 5/60\n\u001b[1m1242/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3745 - loss: 1.7431\nEpoch 5: val_loss improved from 1.71995 to 1.68067, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3746 - loss: 1.7431 - val_accuracy: 0.3879 - val_loss: 1.6807\nEpoch 6/60\n\u001b[1m1237/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3887 - loss: 1.7111\nEpoch 6: val_loss improved from 1.68067 to 1.58463, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3887 - loss: 1.7112 - val_accuracy: 0.4269 - val_loss: 1.5846\nEpoch 7/60\n\u001b[1m1244/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3837 - loss: 1.7086\nEpoch 7: val_loss did not improve from 1.58463\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3837 - loss: 1.7086 - val_accuracy: 0.4270 - val_loss: 1.6091\nEpoch 8/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3916 - loss: 1.6959\nEpoch 8: val_loss improved from 1.58463 to 1.58159, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3916 - loss: 1.6959 - val_accuracy: 0.4345 - val_loss: 1.5816\nEpoch 9/60\n\u001b[1m1245/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3871 - loss: 1.6988\nEpoch 9: val_loss did not improve from 1.58159\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3871 - loss: 1.6989 - val_accuracy: 0.4291 - val_loss: 1.5914\nEpoch 10/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3904 - loss: 1.7055\nEpoch 10: val_loss improved from 1.58159 to 1.56550, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3904 - loss: 1.7055 - val_accuracy: 0.4341 - val_loss: 1.5655\nEpoch 11/60\n\u001b[1m1246/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3975 - loss: 1.6883\nEpoch 11: val_loss did not improve from 1.56550\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3974 - loss: 1.6883 - val_accuracy: 0.4290 - val_loss: 1.5872\nEpoch 12/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4035 - loss: 1.6675\nEpoch 12: val_loss did not improve from 1.56550\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4035 - loss: 1.6675 - val_accuracy: 0.4347 - val_loss: 1.5673\nEpoch 13/60\n\u001b[1m1243/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3980 - loss: 1.6762\nEpoch 13: val_loss improved from 1.56550 to 1.54831, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3980 - loss: 1.6762 - val_accuracy: 0.4384 - val_loss: 1.5483\nEpoch 14/60\n\u001b[1m1239/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4022 - loss: 1.6731\nEpoch 14: val_loss improved from 1.54831 to 1.52064, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4022 - loss: 1.6731 - val_accuracy: 0.4546 - val_loss: 1.5206\nEpoch 15/60\n\u001b[1m1240/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3997 - loss: 1.6746\nEpoch 15: val_loss did not improve from 1.52064\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3998 - loss: 1.6746 - val_accuracy: 0.4402 - val_loss: 1.5481\nEpoch 16/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4101 - loss: 1.6559\nEpoch 16: val_loss did not improve from 1.52064\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4101 - loss: 1.6560 - val_accuracy: 0.4493 - val_loss: 1.5396\nEpoch 17/60\n\u001b[1m1243/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4080 - loss: 1.6548\nEpoch 17: val_loss did not improve from 1.52064\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4080 - loss: 1.6548 - val_accuracy: 0.4354 - val_loss: 1.6050\nEpoch 18/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4038 - loss: 1.6620\nEpoch 18: val_loss did not improve from 1.52064\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4038 - loss: 1.6620 - val_accuracy: 0.4557 - val_loss: 1.5297\nEpoch 19/60\n\u001b[1m1244/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4058 - loss: 1.6554\nEpoch 19: val_loss did not improve from 1.52064\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4058 - loss: 1.6554 - val_accuracy: 0.4571 - val_loss: 1.5225\nEpoch 20/60\n\u001b[1m1237/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4106 - loss: 1.6571\nEpoch 20: val_loss did not improve from 1.52064\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4105 - loss: 1.6572 - val_accuracy: 0.4437 - val_loss: 1.6033\nEpoch 21/60\n\u001b[1m1238/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4095 - loss: 1.6548\nEpoch 21: val_loss improved from 1.52064 to 1.51470, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4095 - loss: 1.6549 - val_accuracy: 0.4642 - val_loss: 1.5147\nEpoch 22/60\n\u001b[1m1242/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4075 - loss: 1.6589\nEpoch 22: val_loss did not improve from 1.51470\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4075 - loss: 1.6589 - val_accuracy: 0.4588 - val_loss: 1.5322\nEpoch 23/60\n\u001b[1m1242/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4089 - loss: 1.6518\nEpoch 23: val_loss improved from 1.51470 to 1.51254, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4089 - loss: 1.6518 - val_accuracy: 0.4553 - val_loss: 1.5125\nEpoch 24/60\n\u001b[1m1238/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4093 - loss: 1.6606\nEpoch 24: val_loss did not improve from 1.51254\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4093 - loss: 1.6604 - val_accuracy: 0.4530 - val_loss: 1.5189\nEpoch 25/60\n\u001b[1m1241/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4120 - loss: 1.6405\nEpoch 25: val_loss did not improve from 1.51254\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4120 - loss: 1.6406 - val_accuracy: 0.4545 - val_loss: 1.5336\nEpoch 26/60\n\u001b[1m1243/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4057 - loss: 1.6533\nEpoch 26: val_loss did not improve from 1.51254\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4058 - loss: 1.6533 - val_accuracy: 0.4521 - val_loss: 1.5265\nEpoch 27/60\n\u001b[1m1245/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4117 - loss: 1.6483\nEpoch 27: val_loss did not improve from 1.51254\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4117 - loss: 1.6483 - val_accuracy: 0.4562 - val_loss: 1.5132\nEpoch 28/60\n\u001b[1m1238/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4119 - loss: 1.6448\nEpoch 28: val_loss improved from 1.51254 to 1.50608, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4119 - loss: 1.6448 - val_accuracy: 0.4604 - val_loss: 1.5061\nEpoch 29/60\n\u001b[1m1244/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4139 - loss: 1.6420\nEpoch 29: val_loss did not improve from 1.50608\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4139 - loss: 1.6420 - val_accuracy: 0.4533 - val_loss: 1.5348\nEpoch 30/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4221 - loss: 1.6219\nEpoch 30: val_loss did not improve from 1.50608\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4221 - loss: 1.6219 - val_accuracy: 0.4468 - val_loss: 1.5370\nEpoch 31/60\n\u001b[1m1241/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4227 - loss: 1.6302\nEpoch 31: val_loss improved from 1.50608 to 1.50291, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4227 - loss: 1.6302 - val_accuracy: 0.4639 - val_loss: 1.5029\nEpoch 32/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4214 - loss: 1.6265\nEpoch 32: val_loss did not improve from 1.50291\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4214 - loss: 1.6265 - val_accuracy: 0.4662 - val_loss: 1.5125\nEpoch 33/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4180 - loss: 1.6241\nEpoch 33: val_loss did not improve from 1.50291\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4180 - loss: 1.6241 - val_accuracy: 0.4613 - val_loss: 1.5380\nEpoch 34/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4156 - loss: 1.6372\nEpoch 34: val_loss did not improve from 1.50291\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4156 - loss: 1.6372 - val_accuracy: 0.4490 - val_loss: 1.5533\nEpoch 35/60\n\u001b[1m1239/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4174 - loss: 1.6366\nEpoch 35: val_loss did not improve from 1.50291\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4174 - loss: 1.6366 - val_accuracy: 0.4637 - val_loss: 1.5078\nEpoch 36/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4209 - loss: 1.6292\nEpoch 36: val_loss did not improve from 1.50291\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4209 - loss: 1.6293 - val_accuracy: 0.4575 - val_loss: 1.5093\nEpoch 37/60\n\u001b[1m1244/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4234 - loss: 1.6196\nEpoch 37: val_loss did not improve from 1.50291\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4234 - loss: 1.6197 - val_accuracy: 0.4580 - val_loss: 1.5045\nEpoch 38/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4149 - loss: 1.6338\nEpoch 38: val_loss improved from 1.50291 to 1.50036, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4149 - loss: 1.6338 - val_accuracy: 0.4647 - val_loss: 1.5004\nEpoch 39/60\n\u001b[1m1246/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4225 - loss: 1.6244\nEpoch 39: val_loss improved from 1.50036 to 1.48603, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4225 - loss: 1.6245 - val_accuracy: 0.4705 - val_loss: 1.4860\nEpoch 40/60\n\u001b[1m1245/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4147 - loss: 1.6331\nEpoch 40: val_loss did not improve from 1.48603\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4147 - loss: 1.6331 - val_accuracy: 0.4660 - val_loss: 1.4918\nEpoch 41/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4121 - loss: 1.6479\nEpoch 41: val_loss did not improve from 1.48603\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4121 - loss: 1.6479 - val_accuracy: 0.4527 - val_loss: 1.5122\nEpoch 42/60\n\u001b[1m1237/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4167 - loss: 1.6367\nEpoch 42: val_loss did not improve from 1.48603\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4167 - loss: 1.6366 - val_accuracy: 0.4469 - val_loss: 1.5352\nEpoch 43/60\n\u001b[1m1239/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4195 - loss: 1.6149\nEpoch 43: val_loss improved from 1.48603 to 1.46906, saving model to cifar10_model.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4195 - loss: 1.6149 - val_accuracy: 0.4778 - val_loss: 1.4691\nEpoch 44/60\n\u001b[1m1245/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4286 - loss: 1.6119\nEpoch 44: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4286 - loss: 1.6119 - val_accuracy: 0.4674 - val_loss: 1.4946\nEpoch 45/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4284 - loss: 1.6046\nEpoch 45: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4284 - loss: 1.6046 - val_accuracy: 0.4643 - val_loss: 1.5061\nEpoch 46/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4268 - loss: 1.6130\nEpoch 46: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4268 - loss: 1.6130 - val_accuracy: 0.4539 - val_loss: 1.5476\nEpoch 47/60\n\u001b[1m1240/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4224 - loss: 1.6081\nEpoch 47: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4224 - loss: 1.6082 - val_accuracy: 0.4557 - val_loss: 1.5142\nEpoch 48/60\n\u001b[1m1243/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4269 - loss: 1.6094\nEpoch 48: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4269 - loss: 1.6094 - val_accuracy: 0.4645 - val_loss: 1.4818\nEpoch 49/60\n\u001b[1m1246/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4261 - loss: 1.6085\nEpoch 49: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4261 - loss: 1.6085 - val_accuracy: 0.4782 - val_loss: 1.4805\nEpoch 50/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4314 - loss: 1.6071\nEpoch 50: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4314 - loss: 1.6071 - val_accuracy: 0.4728 - val_loss: 1.4758\nEpoch 51/60\n\u001b[1m1242/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4325 - loss: 1.6007\nEpoch 51: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4325 - loss: 1.6007 - val_accuracy: 0.4731 - val_loss: 1.4772\nEpoch 52/60\n\u001b[1m1238/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4311 - loss: 1.5962\nEpoch 52: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4311 - loss: 1.5962 - val_accuracy: 0.4742 - val_loss: 1.4834\nEpoch 53/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4298 - loss: 1.5876\nEpoch 53: val_loss did not improve from 1.46906\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4298 - loss: 1.5877 - val_accuracy: 0.4699 - val_loss: 1.4905\nEpoch 53: early stopping\nRestoring model weights from the end of the best epoch: 43.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 테스트 데이터셋을 이용해 모델을 평가합니다.\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:27:18.189387Z","iopub.execute_input":"2025-06-11T17:27:18.189687Z","iopub.status.idle":"2025-06-11T17:27:19.324101Z","shell.execute_reply.started":"2025-06-11T17:27:18.189664Z","shell.execute_reply":"2025-06-11T17:27:19.323346Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4807 - loss: 1.4466\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[1.4536702632904053, 0.4771000146865845]"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### 02 CNN실험\n- CNN 실험 내용\n  - 초기 : 간단한 CNN 구조 적용\n  - 실험-1 : 데이터 증강, 모델층 깊게 하기\n  - 실험-2 : 학습 스케쥴러, 분류층 깊게 만들기\n  - 전이학습 1차 EfficientNetB0(초기 학습 epoch = 50, fine-tuning epoch = 30)\n  - 전이학습 2차 EfficientNetB0(초기 학습 epoch = 60, fine-tuning epoch = 60)\n    - 거의 2시간 가까이 소모","metadata":{}},{"cell_type":"markdown","source":"### 02-01 CNN 초기\n- 간단한 형태의 CNN 구조 적용","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.datasets import cifar10\n\n(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n# 훈련 데이터셋에서 20%를 검증 데이터셋으로 분리\nx_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full,\n                                                  test_size=0.2,\n                                                  random_state=42)\n\n# 정규화\nx_train = x_train.astype('float32')/255.0\nx_val = x_val.astype('float32')/255.0\nx_test = x_test.astype('float32')/255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T08:04:57.823001Z","iopub.execute_input":"2025-06-13T08:04:57.823323Z","iopub.status.idle":"2025-06-13T08:05:21.350564Z","shell.execute_reply.started":"2025-06-13T08:04:57.823303Z","shell.execute_reply":"2025-06-13T08:05:21.349938Z"}},"outputs":[{"name":"stderr","text":"2025-06-13 08:05:00.715728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749801900.965589      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749801901.037564      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras import models, layers\n\n# --- CNN 모델 정의 ---\nmodel = models.Sequential()\n\n# 입력 형태는 (32, 32, 3)입니다. CIFAR-10 등 RGB 이미지\nmodel.add(layers.Input(shape=(32, 32, 3)))\n\n# 특징 추출 부분 (Feature Extraction)\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D((2, 2)))  # 대소문자 정확히\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# 분류 부분 (Classifier)\nmodel.add(layers.Flatten())  # 2D → 1D\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation='softmax'))  # 10-class 분류\n\n# 모델 컴파일\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T08:45:10.957204Z","iopub.execute_input":"2025-06-13T08:45:10.957506Z","iopub.status.idle":"2025-06-13T08:45:14.541297Z","shell.execute_reply.started":"2025-06-13T08:45:10.957483Z","shell.execute_reply":"2025-06-13T08:45:14.540411Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1749804312.849949      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1749804312.850735      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\n# 콜백 정의(ModelCheckPoint, EarlyStopping)\ncheck_point_cb = ModelCheckpoint(\n    filepath = 'cifar10_model_cnn.keras',\n    monitor = 'val_loss',\n    mode = 'min',\n    save_best_only = True,\n    verbose = 1\n)\n\nearly_stopping_cb = EarlyStopping(\n    monitor='val_loss',\n    patience=10,                          # 개선 없으면 중단\n    restore_best_weights=True,           # 가장 좋은 가중치 복원\n    verbose=1\n)\n\nhistory_cnn_1 = model.fit(x_train, y_train,\n                          epochs = 60,\n                          validation_data = (x_val, y_val),\n                          callbacks=[check_point_cb, early_stopping_cb])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T08:45:39.418287Z","iopub.execute_input":"2025-06-13T08:45:39.419152Z","iopub.status.idle":"2025-06-13T08:47:46.498443Z","shell.execute_reply.started":"2025-06-13T08:45:39.419121Z","shell.execute_reply":"2025-06-13T08:47:46.497639Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1749804342.822870     111 service.cc:148] XLA service 0x7f575800aba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1749804342.823452     111 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749804342.823469     111 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749804343.127423     111 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  57/1250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1165 - loss: 2.3086","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749804346.049189     111 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1238/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3024 - loss: 1.8747\nEpoch 1: val_loss improved from inf to 1.32480, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.3033 - loss: 1.8726 - val_accuracy: 0.5271 - val_loss: 1.3248\nEpoch 2/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4941 - loss: 1.3974\nEpoch 2: val_loss improved from 1.32480 to 1.17087, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4941 - loss: 1.3973 - val_accuracy: 0.5947 - val_loss: 1.1709\nEpoch 3/60\n\u001b[1m1243/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5570 - loss: 1.2407\nEpoch 3: val_loss improved from 1.17087 to 1.06114, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5570 - loss: 1.2406 - val_accuracy: 0.6280 - val_loss: 1.0611\nEpoch 4/60\n\u001b[1m1245/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 1.1495\nEpoch 4: val_loss improved from 1.06114 to 1.03571, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5861 - loss: 1.1494 - val_accuracy: 0.6376 - val_loss: 1.0357\nEpoch 5/60\n\u001b[1m1235/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 1.0731\nEpoch 5: val_loss improved from 1.03571 to 1.01682, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6161 - loss: 1.0730 - val_accuracy: 0.6430 - val_loss: 1.0168\nEpoch 6/60\n\u001b[1m1246/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6409 - loss: 1.0138\nEpoch 6: val_loss improved from 1.01682 to 0.93170, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 1.0138 - val_accuracy: 0.6692 - val_loss: 0.9317\nEpoch 7/60\n\u001b[1m1245/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6679 - loss: 0.9478\nEpoch 7: val_loss improved from 0.93170 to 0.92940, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 0.9479 - val_accuracy: 0.6734 - val_loss: 0.9294\nEpoch 8/60\n\u001b[1m1239/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6781 - loss: 0.9057\nEpoch 8: val_loss improved from 0.92940 to 0.89879, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.9058 - val_accuracy: 0.6849 - val_loss: 0.8988\nEpoch 9/60\n\u001b[1m1241/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.8705\nEpoch 9: val_loss improved from 0.89879 to 0.89563, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6885 - loss: 0.8705 - val_accuracy: 0.6878 - val_loss: 0.8956\nEpoch 10/60\n\u001b[1m1235/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6976 - loss: 0.8475\nEpoch 10: val_loss did not improve from 0.89563\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 0.8475 - val_accuracy: 0.6819 - val_loss: 0.9164\nEpoch 11/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.7966\nEpoch 11: val_loss did not improve from 0.89563\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.7966 - val_accuracy: 0.6939 - val_loss: 0.8966\nEpoch 12/60\n\u001b[1m1242/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.7764\nEpoch 12: val_loss did not improve from 0.89563\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7191 - loss: 0.7764 - val_accuracy: 0.6947 - val_loss: 0.9033\nEpoch 13/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.7389\nEpoch 13: val_loss did not improve from 0.89563\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.7389 - val_accuracy: 0.6919 - val_loss: 0.9139\nEpoch 14/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7415 - loss: 0.7196\nEpoch 14: val_loss did not improve from 0.89563\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.7196 - val_accuracy: 0.6887 - val_loss: 0.9133\nEpoch 15/60\n\u001b[1m1234/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.6927\nEpoch 15: val_loss did not improve from 0.89563\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7468 - loss: 0.6929 - val_accuracy: 0.6990 - val_loss: 0.9058\nEpoch 16/60\n\u001b[1m1238/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.6714\nEpoch 16: val_loss improved from 0.89563 to 0.88346, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.6715 - val_accuracy: 0.7069 - val_loss: 0.8835\nEpoch 17/60\n\u001b[1m1234/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7595 - loss: 0.6580\nEpoch 17: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.6581 - val_accuracy: 0.6998 - val_loss: 0.9169\nEpoch 18/60\n\u001b[1m1237/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.6317\nEpoch 18: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.6319 - val_accuracy: 0.6957 - val_loss: 0.9536\nEpoch 19/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.6075\nEpoch 19: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.6075 - val_accuracy: 0.6918 - val_loss: 0.9560\nEpoch 20/60\n\u001b[1m1239/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7793 - loss: 0.5836\nEpoch 20: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7793 - loss: 0.5838 - val_accuracy: 0.7029 - val_loss: 0.9383\nEpoch 21/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5670\nEpoch 21: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.5671 - val_accuracy: 0.7016 - val_loss: 0.9433\nEpoch 22/60\n\u001b[1m1234/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5483\nEpoch 22: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.5486 - val_accuracy: 0.6942 - val_loss: 0.9987\nEpoch 23/60\n\u001b[1m1245/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.5376\nEpoch 23: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.5377 - val_accuracy: 0.7037 - val_loss: 0.9885\nEpoch 24/60\n\u001b[1m1244/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8016 - loss: 0.5256\nEpoch 24: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.5257 - val_accuracy: 0.6917 - val_loss: 0.9943\nEpoch 25/60\n\u001b[1m1235/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.5070\nEpoch 25: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.5072 - val_accuracy: 0.7011 - val_loss: 1.0406\nEpoch 26/60\n\u001b[1m1241/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.4982\nEpoch 26: val_loss did not improve from 0.88346\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4983 - val_accuracy: 0.7012 - val_loss: 1.0368\nEpoch 26: early stopping\nRestoring model weights from the end of the best epoch: 16.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 테스트 데이터셋을 이용해 모델을 평가합니다.\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T08:47:49.659513Z","iopub.execute_input":"2025-06-13T08:47:49.660107Z","iopub.status.idle":"2025-06-13T08:47:50.787651Z","shell.execute_reply.started":"2025-06-13T08:47:49.660084Z","shell.execute_reply":"2025-06-13T08:47:50.787090Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7020 - loss: 0.8889\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[0.8940004706382751, 0.704200029373169]"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"#### 02-02 CNN 실험-1\n- 데이터 증강\n- 모델층을 더 깊게하기","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.datasets import cifar10\n\n(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n# 훈련 데이터셋에서 20%를 검증 데이터셋으로 분리\nx_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, \n                                                  test_size=0.2, \n                                                  random_state=42)\n\n# 정규화\nx_train = x_train.astype('float32')/255.0\nx_val = x_val.astype('float32')/255.0\nx_test = x_test.astype('float32')/255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:38:32.508237Z","iopub.execute_input":"2025-06-11T17:38:32.508974Z","iopub.status.idle":"2025-06-11T17:38:35.203883Z","shell.execute_reply.started":"2025-06-11T17:38:32.508946Z","shell.execute_reply":"2025-06-11T17:38:35.203031Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 데이터 증강\ndata_augmentation = models.Sequential([\n  layers.RandomFlip(\"horizontal\"),\n  layers.RandomRotation(0.1),\n  layers.RandomZoom(0.1),\n])\n\n# --- CNN 모델 정의 ---\nmodel = models.Sequential()\n\n# 입력 형태는 (32, 32, 3) 입니다. # 이미지를 그대로 받음\nmodel.add(layers.Input(shape=(32, 32, 3)))\nmodel.add(data_augmentation) # <-- 데이터 증강 레이어를 모델의 맨 앞에 추가\n\n# 특징 추출 부분 (Feature Extraction)\n\nmodel.add(layers.Conv2D(64, (3, 3), padding='same'))\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu'))   # <-- 활성화 함수를 분리\nmodel.add(layers.Conv2D(64, (3, 3), padding='same'))\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu'))   # <-- 활성화 함수를 분리\nmodel.add(layers.MaxPooling2D((2,2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), padding='same')) #<-- 필터 수 증가\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu')) # <-- 활성화 함수를 분리\nmodel.add(layers.Conv2D(128, (3, 3), padding='same')) #<-- Conv 레이어 추가\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu')) # <-- 활성화 함수를 분리\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# 분류 부분 (Classifier)\nmodel.add(layers.Flatten()) # 2D 특징 맵을 1D 벡터로 변환\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation='softmax')) # 10개 클래스로 분류\n\n# 모델 컴파일\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:40:00.796761Z","iopub.execute_input":"2025-06-11T17:40:00.797494Z","iopub.status.idle":"2025-06-11T17:40:00.988293Z","shell.execute_reply.started":"2025-06-11T17:40:00.797460Z","shell.execute_reply":"2025-06-11T17:40:00.987615Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\n# 콜백 정의(ModelCheckPoint, EarlyStopping)\ncheck_point_cb = ModelCheckpoint(\n    filepath = 'cifar10_model_cnn.keras',\n    monitor = 'val_loss',\n    mode = 'min',\n    save_best_only = True,\n    verbose = 1\n)\n\nearly_stopping_cb = EarlyStopping(\n    monitor='val_loss',\n    patience=10,                          # 개선 없으면 중단\n    restore_best_weights=True,           # 가장 좋은 가중치 복원\n    verbose=1\n)\n\nhistory_cnn_2 = model.fit(x_train, y_train,\n                          epochs = 60,\n                          validation_data = (x_val, y_val),\n                          callbacks=[check_point_cb, early_stopping_cb])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:40:09.920077Z","iopub.execute_input":"2025-06-11T17:40:09.920607Z","iopub.status.idle":"2025-06-11T17:53:52.614047Z","shell.execute_reply.started":"2025-06-11T17:40:09.920583Z","shell.execute_reply":"2025-06-11T17:53:52.613433Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1506 - loss: 2.3472\nEpoch 1: val_loss improved from inf to 2.00367, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.1506 - loss: 2.3468 - val_accuracy: 0.1966 - val_loss: 2.0037\nEpoch 2/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1436 - loss: 2.1310\nEpoch 2: val_loss improved from 2.00367 to 1.95110, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.1437 - loss: 2.1310 - val_accuracy: 0.2015 - val_loss: 1.9511\nEpoch 3/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1475 - loss: 2.1026\nEpoch 3: val_loss did not improve from 1.95110\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.1475 - loss: 2.1026 - val_accuracy: 0.2250 - val_loss: 1.9540\nEpoch 4/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1574 - loss: 2.0906\nEpoch 4: val_loss improved from 1.95110 to 1.89289, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.1574 - loss: 2.0906 - val_accuracy: 0.2487 - val_loss: 1.8929\nEpoch 5/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1612 - loss: 2.0859\nEpoch 5: val_loss did not improve from 1.89289\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.1612 - loss: 2.0859 - val_accuracy: 0.2558 - val_loss: 1.9402\nEpoch 6/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1736 - loss: 2.0544\nEpoch 6: val_loss improved from 1.89289 to 1.77660, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.1737 - loss: 2.0543 - val_accuracy: 0.3179 - val_loss: 1.7766\nEpoch 7/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2034 - loss: 1.9764\nEpoch 7: val_loss improved from 1.77660 to 1.74956, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.2034 - loss: 1.9764 - val_accuracy: 0.3079 - val_loss: 1.7496\nEpoch 8/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2328 - loss: 1.9207\nEpoch 8: val_loss improved from 1.74956 to 1.60814, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.2329 - loss: 1.9206 - val_accuracy: 0.3589 - val_loss: 1.6081\nEpoch 9/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2861 - loss: 1.7992\nEpoch 9: val_loss did not improve from 1.60814\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.2861 - loss: 1.7991 - val_accuracy: 0.4299 - val_loss: 1.6110\nEpoch 10/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3487 - loss: 1.6677\nEpoch 10: val_loss improved from 1.60814 to 1.35175, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.3487 - loss: 1.6676 - val_accuracy: 0.5277 - val_loss: 1.3517\nEpoch 11/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3958 - loss: 1.5847\nEpoch 11: val_loss did not improve from 1.35175\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.3958 - loss: 1.5846 - val_accuracy: 0.5257 - val_loss: 1.4072\nEpoch 12/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4280 - loss: 1.5079\nEpoch 12: val_loss improved from 1.35175 to 1.22978, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.4280 - loss: 1.5079 - val_accuracy: 0.5900 - val_loss: 1.2298\nEpoch 13/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4475 - loss: 1.4784\nEpoch 13: val_loss improved from 1.22978 to 1.17280, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.4475 - loss: 1.4784 - val_accuracy: 0.5984 - val_loss: 1.1728\nEpoch 14/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4701 - loss: 1.4464\nEpoch 14: val_loss improved from 1.17280 to 1.11390, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.4702 - loss: 1.4464 - val_accuracy: 0.6256 - val_loss: 1.1139\nEpoch 15/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4744 - loss: 1.4295\nEpoch 15: val_loss improved from 1.11390 to 1.03872, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.4745 - loss: 1.4294 - val_accuracy: 0.6499 - val_loss: 1.0387\nEpoch 16/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4940 - loss: 1.3824\nEpoch 16: val_loss did not improve from 1.03872\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.4940 - loss: 1.3824 - val_accuracy: 0.6478 - val_loss: 1.0901\nEpoch 17/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5003 - loss: 1.3665\nEpoch 17: val_loss did not improve from 1.03872\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5003 - loss: 1.3665 - val_accuracy: 0.6276 - val_loss: 1.0690\nEpoch 18/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5082 - loss: 1.3438\nEpoch 18: val_loss did not improve from 1.03872\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5082 - loss: 1.3438 - val_accuracy: 0.6522 - val_loss: 1.0414\nEpoch 19/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5166 - loss: 1.3381\nEpoch 19: val_loss improved from 1.03872 to 0.99147, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5166 - loss: 1.3381 - val_accuracy: 0.6742 - val_loss: 0.9915\nEpoch 20/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5239 - loss: 1.3207\nEpoch 20: val_loss improved from 0.99147 to 0.97601, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5239 - loss: 1.3207 - val_accuracy: 0.6534 - val_loss: 0.9760\nEpoch 21/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5423 - loss: 1.2606\nEpoch 21: val_loss improved from 0.97601 to 0.97534, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5423 - loss: 1.2607 - val_accuracy: 0.6773 - val_loss: 0.9753\nEpoch 22/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5359 - loss: 1.2721\nEpoch 22: val_loss improved from 0.97534 to 0.91078, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5359 - loss: 1.2721 - val_accuracy: 0.6921 - val_loss: 0.9108\nEpoch 23/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5477 - loss: 1.2417\nEpoch 23: val_loss did not improve from 0.91078\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5477 - loss: 1.2417 - val_accuracy: 0.6834 - val_loss: 0.9187\nEpoch 24/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5463 - loss: 1.2507\nEpoch 24: val_loss did not improve from 0.91078\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5463 - loss: 1.2507 - val_accuracy: 0.6604 - val_loss: 0.9908\nEpoch 25/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5604 - loss: 1.2159\nEpoch 25: val_loss did not improve from 0.91078\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5604 - loss: 1.2159 - val_accuracy: 0.6443 - val_loss: 1.0416\nEpoch 26/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5637 - loss: 1.2085\nEpoch 26: val_loss did not improve from 0.91078\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5637 - loss: 1.2085 - val_accuracy: 0.6717 - val_loss: 1.0127\nEpoch 27/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5889 - loss: 1.1489\nEpoch 27: val_loss did not improve from 0.91078\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5889 - loss: 1.1489 - val_accuracy: 0.6877 - val_loss: 0.9379\nEpoch 28/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5874 - loss: 1.1435\nEpoch 28: val_loss improved from 0.91078 to 0.83389, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5874 - loss: 1.1435 - val_accuracy: 0.7140 - val_loss: 0.8339\nEpoch 29/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5967 - loss: 1.1254\nEpoch 29: val_loss did not improve from 0.83389\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5967 - loss: 1.1255 - val_accuracy: 0.7212 - val_loss: 0.8501\nEpoch 30/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5932 - loss: 1.1257\nEpoch 30: val_loss did not improve from 0.83389\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5932 - loss: 1.1257 - val_accuracy: 0.7149 - val_loss: 0.8556\nEpoch 31/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6056 - loss: 1.1022\nEpoch 31: val_loss improved from 0.83389 to 0.77899, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6056 - loss: 1.1021 - val_accuracy: 0.7445 - val_loss: 0.7790\nEpoch 32/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6111 - loss: 1.0859\nEpoch 32: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6111 - loss: 1.0859 - val_accuracy: 0.7066 - val_loss: 0.8590\nEpoch 33/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6182 - loss: 1.0662\nEpoch 33: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6182 - loss: 1.0662 - val_accuracy: 0.7162 - val_loss: 0.8525\nEpoch 34/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6290 - loss: 1.0505\nEpoch 34: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6290 - loss: 1.0505 - val_accuracy: 0.7089 - val_loss: 0.8601\nEpoch 35/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6352 - loss: 1.0270\nEpoch 35: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6352 - loss: 1.0270 - val_accuracy: 0.7094 - val_loss: 0.9005\nEpoch 36/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6336 - loss: 1.0382\nEpoch 36: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6336 - loss: 1.0382 - val_accuracy: 0.7325 - val_loss: 0.8141\nEpoch 37/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6453 - loss: 1.0013\nEpoch 37: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6453 - loss: 1.0013 - val_accuracy: 0.7376 - val_loss: 0.8194\nEpoch 38/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6650 - loss: 0.9552\nEpoch 38: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6650 - loss: 0.9552 - val_accuracy: 0.7390 - val_loss: 0.8164\nEpoch 39/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6663 - loss: 0.9422\nEpoch 39: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6663 - loss: 0.9422 - val_accuracy: 0.7445 - val_loss: 0.7871\nEpoch 40/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6666 - loss: 0.9562\nEpoch 40: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6666 - loss: 0.9562 - val_accuracy: 0.7433 - val_loss: 0.8256\nEpoch 41/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6700 - loss: 0.9341\nEpoch 41: val_loss did not improve from 0.77899\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.9341 - val_accuracy: 0.7262 - val_loss: 0.9388\nEpoch 41: early stopping\nRestoring model weights from the end of the best epoch: 31.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 테스트 데이터셋을 이용해 모델을 평가합니다.\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T17:53:59.460534Z","iopub.execute_input":"2025-06-11T17:53:59.461259Z","iopub.status.idle":"2025-06-11T17:54:01.355428Z","shell.execute_reply.started":"2025-06-11T17:53:59.461236Z","shell.execute_reply":"2025-06-11T17:54:01.354851Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7405 - loss: 0.7974\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[0.8025781512260437, 0.739300012588501]"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"#### 02-03 CNN-실험2\n- 좀 더 fine-tuning할게 있는지?","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras import models, layers, optimizers  # optimizers추가\nfrom tensorflow.keras.datasets import cifar10\n\n(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n# 훈련 데이터셋에서 20%를 검증 데이터셋으로 분리\nx_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, \n                                                  test_size=0.2, \n                                                  random_state=42)\n\n# 정규화\nx_train = x_train.astype('float32')/255.0\nx_val = x_val.astype('float32')/255.0\nx_test = x_test.astype('float32')/255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T18:36:40.056243Z","iopub.execute_input":"2025-06-11T18:36:40.056471Z","iopub.status.idle":"2025-06-11T18:37:07.918629Z","shell.execute_reply.started":"2025-06-11T18:36:40.056452Z","shell.execute_reply":"2025-06-11T18:37:07.917835Z"}},"outputs":[{"name":"stderr","text":"2025-06-11 18:36:46.044844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749667006.477768      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749667006.595413      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 데이터 증강\ndata_augmentation = models.Sequential([\n  layers.RandomFlip(\"horizontal\"),\n  layers.RandomRotation(0.1),\n  layers.RandomZoom(0.1),\n])\n\n# --- CNN 모델 정의 ---\nmodel = models.Sequential()\n\n# 입력 형태는 (32, 32, 3) 입니다. # 이미지를 그대로 받음\nmodel.add(layers.Input(shape=(32, 32, 3)))\nmodel.add(data_augmentation) # <-- 데이터 증강 레이어를 모델의 맨 앞에 추가\n\n# 특징 추출 부분 (Feature Extraction)\n\nmodel.add(layers.Conv2D(64, (3, 3), padding='same'))\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu'))   # <-- 활성화 함수를 분리\nmodel.add(layers.Conv2D(64, (3, 3), padding='same'))\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu'))   # <-- 활성화 함수를 분리\nmodel.add(layers.MaxPooling2D((2,2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), padding='same')) #<-- 필터 수 증가\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu')) # <-- 활성화 함수를 분리\nmodel.add(layers.Conv2D(128, (3, 3), padding='same')) #<-- Conv 레이어 추가\nmodel.add(layers.BatchNormalization()) # <-- 배치 정규화 추가\nmodel.add(layers.Activation('relu')) # <-- 활성화 함수를 분리\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# 분류 부분 (Classifier)\nmodel.add(layers.Flatten()) # 2D 특징 맵을 1D 벡터로 변환\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(512, activation='relu')) # <-- 유닛 수를 늘리고\nmodel.add(layers.BatchNormalization())          # <-- BN 추가\nmodel.add(layers.Dense(256, activation='relu')) # <-- 층을 하나 더 추가\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation='softmax')) # 10개 클래스로 분류\n\n# 모델 컴파일\nmodel.compile(optimizer=optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T18:37:18.568258Z","iopub.execute_input":"2025-06-11T18:37:18.568859Z","iopub.status.idle":"2025-06-11T18:37:23.445841Z","shell.execute_reply.started":"2025-06-11T18:37:18.568835Z","shell.execute_reply":"2025-06-11T18:37:23.445062Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1749667041.326655      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1749667041.327503      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n# ReduceLROnPlateau 추가! callback 설정 추가목적\nimport time\n\nst = time.time()\n\n# 콜백 정의(ModelCheckPoint, EarlyStopping)\ncheck_point_cb = ModelCheckpoint(\n    filepath = 'cifar10_model_cnn.keras',\n    monitor = 'val_loss',\n    mode = 'min',\n    save_best_only = True,\n    verbose = 1\n)\n\nearly_stopping_cb = EarlyStopping(\n    monitor='val_loss',\n    patience=10,                          # 개선 없으면 중단\n    restore_best_weights=True,           # 가장 좋은 가중치 복원\n    verbose=1\n)\n\nreduce_lr_cb = ReduceLROnPlateau(\n    monitor = 'val_loss',\n    factor = 0.2,\n    patience = 3, # 3 epoch 동안 개선 없으면 실행\n    verbose = 1\n)\n\nhistory_cnn_3 = model.fit(x_train, y_train,\n                          epochs = 60,\n                          validation_data = (x_val, y_val),\n                          callbacks=[check_point_cb, early_stopping_cb, reduce_lr_cb])\n\ned = time.time()\n\nprint(f'소모시간: {round(ed-st,2)}초')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T18:38:05.146517Z","iopub.execute_input":"2025-06-11T18:38:05.147150Z","iopub.status.idle":"2025-06-11T18:54:07.946090Z","shell.execute_reply.started":"2025-06-11T18:38:05.147114Z","shell.execute_reply":"2025-06-11T18:54:07.945252Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749667094.652926      97 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3517 - loss: 1.8550\nEpoch 1: val_loss improved from inf to 1.81224, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 17ms/step - accuracy: 0.3518 - loss: 1.8544 - val_accuracy: 0.4026 - val_loss: 1.8122 - learning_rate: 0.0010\nEpoch 2/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5319 - loss: 1.3242\nEpoch 2: val_loss improved from 1.81224 to 1.24675, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.5320 - loss: 1.3240 - val_accuracy: 0.5734 - val_loss: 1.2468 - learning_rate: 0.0010\nEpoch 3/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6057 - loss: 1.1405\nEpoch 3: val_loss improved from 1.24675 to 1.03989, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.6057 - loss: 1.1404 - val_accuracy: 0.6438 - val_loss: 1.0399 - learning_rate: 0.0010\nEpoch 4/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6339 - loss: 1.0544\nEpoch 4: val_loss did not improve from 1.03989\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.6340 - loss: 1.0544 - val_accuracy: 0.6101 - val_loss: 1.3239 - learning_rate: 0.0010\nEpoch 5/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6627 - loss: 0.9844\nEpoch 5: val_loss improved from 1.03989 to 0.85632, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.6627 - loss: 0.9844 - val_accuracy: 0.7067 - val_loss: 0.8563 - learning_rate: 0.0010\nEpoch 6/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6845 - loss: 0.9297\nEpoch 6: val_loss did not improve from 0.85632\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.6845 - loss: 0.9296 - val_accuracy: 0.6810 - val_loss: 0.9538 - learning_rate: 0.0010\nEpoch 7/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7023 - loss: 0.8830\nEpoch 7: val_loss did not improve from 0.85632\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7023 - loss: 0.8830 - val_accuracy: 0.7016 - val_loss: 0.9133 - learning_rate: 0.0010\nEpoch 8/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7246 - loss: 0.8169\nEpoch 8: val_loss did not improve from 0.85632\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7246 - loss: 0.8169 - val_accuracy: 0.7244 - val_loss: 0.8789 - learning_rate: 0.0010\nEpoch 9/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7595 - loss: 0.7165\nEpoch 9: val_loss improved from 0.85632 to 0.61139, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7595 - loss: 0.7164 - val_accuracy: 0.7935 - val_loss: 0.6114 - learning_rate: 2.0000e-04\nEpoch 10/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7849 - loss: 0.6421\nEpoch 10: val_loss did not improve from 0.61139\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7849 - loss: 0.6421 - val_accuracy: 0.7789 - val_loss: 0.6711 - learning_rate: 2.0000e-04\nEpoch 11/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7864 - loss: 0.6267\nEpoch 11: val_loss did not improve from 0.61139\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7864 - loss: 0.6267 - val_accuracy: 0.7888 - val_loss: 0.6203 - learning_rate: 2.0000e-04\nEpoch 12/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7945 - loss: 0.6076\nEpoch 12: val_loss did not improve from 0.61139\n\nEpoch 12: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7945 - loss: 0.6077 - val_accuracy: 0.7918 - val_loss: 0.6190 - learning_rate: 2.0000e-04\nEpoch 13/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8031 - loss: 0.5750\nEpoch 13: val_loss improved from 0.61139 to 0.58478, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8031 - loss: 0.5751 - val_accuracy: 0.8049 - val_loss: 0.5848 - learning_rate: 4.0000e-05\nEpoch 14/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8029 - loss: 0.5785\nEpoch 14: val_loss improved from 0.58478 to 0.57461, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8030 - loss: 0.5785 - val_accuracy: 0.8068 - val_loss: 0.5746 - learning_rate: 4.0000e-05\nEpoch 15/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8098 - loss: 0.5635\nEpoch 15: val_loss improved from 0.57461 to 0.56804, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8098 - loss: 0.5635 - val_accuracy: 0.8112 - val_loss: 0.5680 - learning_rate: 4.0000e-05\nEpoch 16/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8063 - loss: 0.5758\nEpoch 16: val_loss did not improve from 0.56804\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8063 - loss: 0.5758 - val_accuracy: 0.8078 - val_loss: 0.5722 - learning_rate: 4.0000e-05\nEpoch 17/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8085 - loss: 0.5557\nEpoch 17: val_loss did not improve from 0.56804\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8085 - loss: 0.5557 - val_accuracy: 0.8077 - val_loss: 0.5752 - learning_rate: 4.0000e-05\nEpoch 18/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8161 - loss: 0.5382\nEpoch 18: val_loss improved from 0.56804 to 0.56178, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8161 - loss: 0.5382 - val_accuracy: 0.8095 - val_loss: 0.5618 - learning_rate: 4.0000e-05\nEpoch 19/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8128 - loss: 0.5530\nEpoch 19: val_loss improved from 0.56178 to 0.55913, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8128 - loss: 0.5530 - val_accuracy: 0.8110 - val_loss: 0.5591 - learning_rate: 4.0000e-05\nEpoch 20/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8160 - loss: 0.5377\nEpoch 20: val_loss did not improve from 0.55913\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8160 - loss: 0.5377 - val_accuracy: 0.8099 - val_loss: 0.5658 - learning_rate: 4.0000e-05\nEpoch 21/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8179 - loss: 0.5384\nEpoch 21: val_loss did not improve from 0.55913\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8179 - loss: 0.5384 - val_accuracy: 0.8117 - val_loss: 0.5617 - learning_rate: 4.0000e-05\nEpoch 22/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8153 - loss: 0.5444\nEpoch 22: val_loss did not improve from 0.55913\n\nEpoch 22: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8153 - loss: 0.5444 - val_accuracy: 0.8128 - val_loss: 0.5601 - learning_rate: 4.0000e-05\nEpoch 23/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8179 - loss: 0.5317\nEpoch 23: val_loss improved from 0.55913 to 0.55754, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8179 - loss: 0.5317 - val_accuracy: 0.8128 - val_loss: 0.5575 - learning_rate: 8.0000e-06\nEpoch 24/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8177 - loss: 0.5378\nEpoch 24: val_loss did not improve from 0.55754\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8177 - loss: 0.5378 - val_accuracy: 0.8128 - val_loss: 0.5586 - learning_rate: 8.0000e-06\nEpoch 25/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8188 - loss: 0.5287\nEpoch 25: val_loss improved from 0.55754 to 0.55561, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8188 - loss: 0.5287 - val_accuracy: 0.8152 - val_loss: 0.5556 - learning_rate: 8.0000e-06\nEpoch 26/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8186 - loss: 0.5381\nEpoch 26: val_loss did not improve from 0.55561\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8186 - loss: 0.5381 - val_accuracy: 0.8141 - val_loss: 0.5567 - learning_rate: 8.0000e-06\nEpoch 27/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8186 - loss: 0.5301\nEpoch 27: val_loss did not improve from 0.55561\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8186 - loss: 0.5301 - val_accuracy: 0.8142 - val_loss: 0.5582 - learning_rate: 8.0000e-06\nEpoch 28/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8193 - loss: 0.5270\nEpoch 28: val_loss did not improve from 0.55561\n\nEpoch 28: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8193 - loss: 0.5270 - val_accuracy: 0.8140 - val_loss: 0.5569 - learning_rate: 8.0000e-06\nEpoch 29/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8224 - loss: 0.5289\nEpoch 29: val_loss improved from 0.55561 to 0.55464, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8224 - loss: 0.5289 - val_accuracy: 0.8144 - val_loss: 0.5546 - learning_rate: 1.6000e-06\nEpoch 30/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8229 - loss: 0.5194\nEpoch 30: val_loss improved from 0.55464 to 0.55444, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8229 - loss: 0.5194 - val_accuracy: 0.8145 - val_loss: 0.5544 - learning_rate: 1.6000e-06\nEpoch 31/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8240 - loss: 0.5220\nEpoch 31: val_loss did not improve from 0.55444\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8240 - loss: 0.5220 - val_accuracy: 0.8146 - val_loss: 0.5558 - learning_rate: 1.6000e-06\nEpoch 32/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8199 - loss: 0.5257\nEpoch 32: val_loss did not improve from 0.55444\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8199 - loss: 0.5257 - val_accuracy: 0.8148 - val_loss: 0.5564 - learning_rate: 1.6000e-06\nEpoch 33/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8206 - loss: 0.5222\nEpoch 33: val_loss did not improve from 0.55444\n\nEpoch 33: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8206 - loss: 0.5222 - val_accuracy: 0.8143 - val_loss: 0.5565 - learning_rate: 1.6000e-06\nEpoch 34/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8210 - loss: 0.5170\nEpoch 34: val_loss improved from 0.55444 to 0.55300, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8210 - loss: 0.5171 - val_accuracy: 0.8142 - val_loss: 0.5530 - learning_rate: 3.2000e-07\nEpoch 35/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8202 - loss: 0.5301\nEpoch 35: val_loss improved from 0.55300 to 0.55170, saving model to cifar10_model_cnn.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8202 - loss: 0.5301 - val_accuracy: 0.8148 - val_loss: 0.5517 - learning_rate: 3.2000e-07\nEpoch 36/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8228 - loss: 0.5198\nEpoch 36: val_loss did not improve from 0.55170\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8228 - loss: 0.5198 - val_accuracy: 0.8146 - val_loss: 0.5560 - learning_rate: 3.2000e-07\nEpoch 37/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8220 - loss: 0.5210\nEpoch 37: val_loss did not improve from 0.55170\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8220 - loss: 0.5210 - val_accuracy: 0.8144 - val_loss: 0.5545 - learning_rate: 3.2000e-07\nEpoch 38/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8213 - loss: 0.5223\nEpoch 38: val_loss did not improve from 0.55170\n\nEpoch 38: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8213 - loss: 0.5223 - val_accuracy: 0.8154 - val_loss: 0.5561 - learning_rate: 3.2000e-07\nEpoch 39/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8216 - loss: 0.5216\nEpoch 39: val_loss did not improve from 0.55170\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8216 - loss: 0.5216 - val_accuracy: 0.8159 - val_loss: 0.5544 - learning_rate: 6.4000e-08\nEpoch 40/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8209 - loss: 0.5289\nEpoch 40: val_loss did not improve from 0.55170\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8209 - loss: 0.5289 - val_accuracy: 0.8140 - val_loss: 0.5543 - learning_rate: 6.4000e-08\nEpoch 41/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8194 - loss: 0.5276\nEpoch 41: val_loss did not improve from 0.55170\n\nEpoch 41: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8194 - loss: 0.5276 - val_accuracy: 0.8144 - val_loss: 0.5529 - learning_rate: 6.4000e-08\nEpoch 42/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8250 - loss: 0.5193\nEpoch 42: val_loss did not improve from 0.55170\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8250 - loss: 0.5193 - val_accuracy: 0.8149 - val_loss: 0.5563 - learning_rate: 1.2800e-08\nEpoch 43/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8216 - loss: 0.5256\nEpoch 43: val_loss did not improve from 0.55170\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8216 - loss: 0.5256 - val_accuracy: 0.8144 - val_loss: 0.5565 - learning_rate: 1.2800e-08\nEpoch 44/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8224 - loss: 0.5218\nEpoch 44: val_loss did not improve from 0.55170\n\nEpoch 44: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8224 - loss: 0.5218 - val_accuracy: 0.8148 - val_loss: 0.5560 - learning_rate: 1.2800e-08\nEpoch 45/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8198 - loss: 0.5284\nEpoch 45: val_loss did not improve from 0.55170\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8198 - loss: 0.5284 - val_accuracy: 0.8148 - val_loss: 0.5552 - learning_rate: 2.5600e-09\nEpoch 45: early stopping\nRestoring model weights from the end of the best epoch: 35.\n소모시간: 962.79초\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 테스트 데이터셋을 이용해 모델을 평가합니다.\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T18:55:50.183166Z","iopub.execute_input":"2025-06-11T18:55:50.183667Z","iopub.status.idle":"2025-06-11T18:55:52.108225Z","shell.execute_reply.started":"2025-06-11T18:55:50.183642Z","shell.execute_reply":"2025-06-11T18:55:52.107640Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.5809\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[0.5742959380149841, 0.807200014591217]"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"#### 02-04 전이학습-1\n- 1차 학습 epoch 50, 2차 학습 epoch 30","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport time\nst = time.time()\n\n# 1. 데이터 로드 및 분할\n(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\nx_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n\n# 2. 데이터 증강 레이어 정의\ndata_augmentation = models.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n], name=\"data_augmentation\")\n\n# --- 모델 구성 ---\n# 3. 기본 모델 로드\nbase_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(75, 75, 3))\nbase_model.trainable = False  # 동결\n\n# 4. Functional API를 사용한 전체 모델 조립\ninputs = layers.Input(shape=(32, 32, 3))\nx = data_augmentation(inputs)\nx = layers.Resizing(75, 75)(x)\nx = preprocess_input(x) # 수동 정규화 대신 여기서 처리\nx = base_model(x, training=False) # training=False 설정이 중요!\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(10, activation='softmax')(x)\n\nmodel = models.Model(inputs, outputs)\n\n# --- 1차 학습 ---\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\ncallbacks_list = [\n    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n    ModelCheckpoint(filepath='cifar10_transfer_best.keras', monitor='val_loss', save_best_only=True, verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)\n]\n\nhistory = model.fit(x_train, y_train,\n                    epochs=50, # 에포크는 조절 가능\n                    validation_data=(x_val, y_val),\n                    callbacks=callbacks_list)\n\n# --- 2차 학습 (미세 조정) ---\nbase_model.trainable = True # 전체 동결 해제\n\n# (선택적) 일부만 동결 해제\n# for layer in base_model.layers[:-20]:\n#     layer.trainable = False\n\nmodel.compile(optimizer=optimizers.Adam(learning_rate=1e-5), # 매우 낮은 학습률\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# initial_epoch를 설정하여 학습 이어가기\nfine_tune_epochs = 30\ntotal_epochs = len(history.epoch) + fine_tune_epochs\n\nfine_tune_history = model.fit(x_train, y_train,\n                              epochs=total_epochs,\n                              initial_epoch=len(history.epoch), # 이전 학습이 끝난 시점부터 시작\n                              validation_data=(x_val, y_val),\n                              callbacks=callbacks_list)\n\n\ned = time.time()\nprint(f'소요시간:{round(ed-st,2)}초')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T19:49:52.424154Z","iopub.execute_input":"2025-06-11T19:49:52.424386Z","iopub.status.idle":"2025-06-11T20:54:14.270033Z","shell.execute_reply.started":"2025-06-11T19:49:52.424369Z","shell.execute_reply":"2025-06-11T20:54:14.269434Z"}},"outputs":[{"name":"stderr","text":"2025-06-11 19:49:54.279552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749671394.505587      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749671394.567141      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749671414.440988      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1749671414.441731      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749671433.246681      35 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nI0000 00:00:1749671435.571496      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5376 - loss: 1.3295\nEpoch 1: val_loss improved from inf to 0.64236, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 23ms/step - accuracy: 0.5377 - loss: 1.3294 - val_accuracy: 0.7807 - val_loss: 0.6424 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6511 - loss: 0.9919\nEpoch 2: val_loss improved from 0.64236 to 0.58537, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6511 - loss: 0.9919 - val_accuracy: 0.8017 - val_loss: 0.5854 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6683 - loss: 0.9541\nEpoch 3: val_loss did not improve from 0.58537\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.6683 - loss: 0.9541 - val_accuracy: 0.7955 - val_loss: 0.5916 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6795 - loss: 0.9272\nEpoch 4: val_loss improved from 0.58537 to 0.57047, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6795 - loss: 0.9272 - val_accuracy: 0.8030 - val_loss: 0.5705 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6834 - loss: 0.9061\nEpoch 5: val_loss improved from 0.57047 to 0.55872, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6834 - loss: 0.9061 - val_accuracy: 0.8091 - val_loss: 0.5587 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6843 - loss: 0.8981\nEpoch 6: val_loss did not improve from 0.55872\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.6843 - loss: 0.8981 - val_accuracy: 0.8035 - val_loss: 0.5592 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6896 - loss: 0.8887\nEpoch 7: val_loss improved from 0.55872 to 0.55436, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6896 - loss: 0.8887 - val_accuracy: 0.8096 - val_loss: 0.5544 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6910 - loss: 0.8762\nEpoch 8: val_loss improved from 0.55436 to 0.54837, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6910 - loss: 0.8762 - val_accuracy: 0.8128 - val_loss: 0.5484 - learning_rate: 0.0010\nEpoch 9/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7013 - loss: 0.8602\nEpoch 9: val_loss improved from 0.54837 to 0.54013, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7013 - loss: 0.8603 - val_accuracy: 0.8097 - val_loss: 0.5401 - learning_rate: 0.0010\nEpoch 10/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7033 - loss: 0.8558\nEpoch 10: val_loss improved from 0.54013 to 0.53702, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7033 - loss: 0.8558 - val_accuracy: 0.8132 - val_loss: 0.5370 - learning_rate: 0.0010\nEpoch 11/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7006 - loss: 0.8550\nEpoch 11: val_loss improved from 0.53702 to 0.53540, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7006 - loss: 0.8550 - val_accuracy: 0.8158 - val_loss: 0.5354 - learning_rate: 0.0010\nEpoch 12/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7042 - loss: 0.8423\nEpoch 12: val_loss improved from 0.53540 to 0.53307, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7042 - loss: 0.8423 - val_accuracy: 0.8167 - val_loss: 0.5331 - learning_rate: 0.0010\nEpoch 13/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7061 - loss: 0.8423\nEpoch 13: val_loss improved from 0.53307 to 0.53204, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7061 - loss: 0.8423 - val_accuracy: 0.8175 - val_loss: 0.5320 - learning_rate: 0.0010\nEpoch 14/50\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7081 - loss: 0.8303\nEpoch 14: val_loss improved from 0.53204 to 0.52999, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7081 - loss: 0.8303 - val_accuracy: 0.8174 - val_loss: 0.5300 - learning_rate: 0.0010\nEpoch 15/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7147 - loss: 0.8162\nEpoch 15: val_loss did not improve from 0.52999\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7147 - loss: 0.8162 - val_accuracy: 0.8191 - val_loss: 0.5301 - learning_rate: 0.0010\nEpoch 16/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7138 - loss: 0.8258\nEpoch 16: val_loss improved from 0.52999 to 0.52407, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7138 - loss: 0.8258 - val_accuracy: 0.8181 - val_loss: 0.5241 - learning_rate: 0.0010\nEpoch 17/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7103 - loss: 0.8304\nEpoch 17: val_loss improved from 0.52407 to 0.52163, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7103 - loss: 0.8304 - val_accuracy: 0.8212 - val_loss: 0.5216 - learning_rate: 0.0010\nEpoch 18/50\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7137 - loss: 0.8144\nEpoch 18: val_loss did not improve from 0.52163\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7137 - loss: 0.8144 - val_accuracy: 0.8181 - val_loss: 0.5285 - learning_rate: 0.0010\nEpoch 19/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7139 - loss: 0.8127\nEpoch 19: val_loss did not improve from 0.52163\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7139 - loss: 0.8127 - val_accuracy: 0.8190 - val_loss: 0.5259 - learning_rate: 0.0010\nEpoch 20/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7187 - loss: 0.8127\nEpoch 20: val_loss did not improve from 0.52163\n\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7187 - loss: 0.8127 - val_accuracy: 0.8216 - val_loss: 0.5221 - learning_rate: 0.0010\nEpoch 21/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7297 - loss: 0.7697\nEpoch 21: val_loss improved from 0.52163 to 0.51109, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7297 - loss: 0.7697 - val_accuracy: 0.8259 - val_loss: 0.5111 - learning_rate: 2.0000e-04\nEpoch 22/50\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7318 - loss: 0.7724\nEpoch 22: val_loss improved from 0.51109 to 0.50636, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7318 - loss: 0.7724 - val_accuracy: 0.8268 - val_loss: 0.5064 - learning_rate: 2.0000e-04\nEpoch 23/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7361 - loss: 0.7626\nEpoch 23: val_loss did not improve from 0.50636\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7361 - loss: 0.7626 - val_accuracy: 0.8240 - val_loss: 0.5093 - learning_rate: 2.0000e-04\nEpoch 24/50\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7359 - loss: 0.7499\nEpoch 24: val_loss did not improve from 0.50636\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7359 - loss: 0.7499 - val_accuracy: 0.8247 - val_loss: 0.5118 - learning_rate: 2.0000e-04\nEpoch 25/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7326 - loss: 0.7557\nEpoch 25: val_loss improved from 0.50636 to 0.50473, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7326 - loss: 0.7557 - val_accuracy: 0.8266 - val_loss: 0.5047 - learning_rate: 2.0000e-04\nEpoch 26/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7372 - loss: 0.7539\nEpoch 26: val_loss did not improve from 0.50473\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7372 - loss: 0.7539 - val_accuracy: 0.8278 - val_loss: 0.5063 - learning_rate: 2.0000e-04\nEpoch 27/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7374 - loss: 0.7438\nEpoch 27: val_loss did not improve from 0.50473\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7374 - loss: 0.7438 - val_accuracy: 0.8266 - val_loss: 0.5069 - learning_rate: 2.0000e-04\nEpoch 28/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7377 - loss: 0.7588\nEpoch 28: val_loss improved from 0.50473 to 0.50099, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7377 - loss: 0.7588 - val_accuracy: 0.8301 - val_loss: 0.5010 - learning_rate: 2.0000e-04\nEpoch 29/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7440 - loss: 0.7337\nEpoch 29: val_loss did not improve from 0.50099\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7440 - loss: 0.7337 - val_accuracy: 0.8278 - val_loss: 0.5011 - learning_rate: 2.0000e-04\nEpoch 30/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7431 - loss: 0.7333\nEpoch 30: val_loss improved from 0.50099 to 0.50084, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7431 - loss: 0.7333 - val_accuracy: 0.8266 - val_loss: 0.5008 - learning_rate: 2.0000e-04\nEpoch 31/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7437 - loss: 0.7387\nEpoch 31: val_loss improved from 0.50084 to 0.49551, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7437 - loss: 0.7387 - val_accuracy: 0.8301 - val_loss: 0.4955 - learning_rate: 2.0000e-04\nEpoch 32/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7431 - loss: 0.7352\nEpoch 32: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7431 - loss: 0.7352 - val_accuracy: 0.8301 - val_loss: 0.4981 - learning_rate: 2.0000e-04\nEpoch 33/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7398 - loss: 0.7415\nEpoch 33: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7398 - loss: 0.7415 - val_accuracy: 0.8296 - val_loss: 0.5004 - learning_rate: 2.0000e-04\nEpoch 34/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7427 - loss: 0.7288\nEpoch 34: val_loss did not improve from 0.49551\n\nEpoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7427 - loss: 0.7288 - val_accuracy: 0.8268 - val_loss: 0.5016 - learning_rate: 2.0000e-04\nEpoch 35/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7442 - loss: 0.7329\nEpoch 35: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7442 - loss: 0.7329 - val_accuracy: 0.8281 - val_loss: 0.4985 - learning_rate: 4.0000e-05\nEpoch 36/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7484 - loss: 0.7208\nEpoch 36: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7484 - loss: 0.7209 - val_accuracy: 0.8290 - val_loss: 0.4992 - learning_rate: 4.0000e-05\nEpoch 37/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7461 - loss: 0.7306\nEpoch 37: val_loss did not improve from 0.49551\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7461 - loss: 0.7306 - val_accuracy: 0.8291 - val_loss: 0.4995 - learning_rate: 4.0000e-05\nEpoch 38/50\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7474 - loss: 0.7285\nEpoch 38: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7474 - loss: 0.7285 - val_accuracy: 0.8292 - val_loss: 0.4993 - learning_rate: 8.0000e-06\nEpoch 39/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7446 - loss: 0.7218\nEpoch 39: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7446 - loss: 0.7218 - val_accuracy: 0.8290 - val_loss: 0.4986 - learning_rate: 8.0000e-06\nEpoch 40/50\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7486 - loss: 0.7133\nEpoch 40: val_loss did not improve from 0.49551\n\nEpoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7486 - loss: 0.7133 - val_accuracy: 0.8287 - val_loss: 0.4989 - learning_rate: 8.0000e-06\nEpoch 41/50\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7516 - loss: 0.7178\nEpoch 41: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7516 - loss: 0.7178 - val_accuracy: 0.8285 - val_loss: 0.4990 - learning_rate: 1.6000e-06\nEpoch 41: early stopping\nRestoring model weights from the end of the best epoch: 31.\nEpoch 42/71\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749672421.036627      35 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4237 - loss: 2.9561\nEpoch 42: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 79ms/step - accuracy: 0.4237 - loss: 2.9557 - val_accuracy: 0.6437 - val_loss: 1.3658 - learning_rate: 1.0000e-05\nEpoch 43/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5563 - loss: 1.7903\nEpoch 43: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 75ms/step - accuracy: 0.5564 - loss: 1.7902 - val_accuracy: 0.7001 - val_loss: 1.0660 - learning_rate: 1.0000e-05\nEpoch 44/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6094 - loss: 1.4003\nEpoch 44: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 75ms/step - accuracy: 0.6094 - loss: 1.4003 - val_accuracy: 0.7345 - val_loss: 0.8703 - learning_rate: 1.0000e-05\nEpoch 45/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6397 - loss: 1.2004\nEpoch 45: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 74ms/step - accuracy: 0.6397 - loss: 1.2003 - val_accuracy: 0.7622 - val_loss: 0.7319 - learning_rate: 1.0000e-05\nEpoch 46/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6736 - loss: 1.0388\nEpoch 46: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 75ms/step - accuracy: 0.6736 - loss: 1.0388 - val_accuracy: 0.7879 - val_loss: 0.6411 - learning_rate: 1.0000e-05\nEpoch 47/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6945 - loss: 0.9329\nEpoch 47: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 74ms/step - accuracy: 0.6945 - loss: 0.9329 - val_accuracy: 0.8054 - val_loss: 0.5827 - learning_rate: 1.0000e-05\nEpoch 48/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7217 - loss: 0.8382\nEpoch 48: val_loss did not improve from 0.49551\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 74ms/step - accuracy: 0.7217 - loss: 0.8382 - val_accuracy: 0.8231 - val_loss: 0.5223 - learning_rate: 1.0000e-05\nEpoch 49/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7361 - loss: 0.7944\nEpoch 49: val_loss improved from 0.49551 to 0.49121, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7361 - loss: 0.7944 - val_accuracy: 0.8320 - val_loss: 0.4912 - learning_rate: 1.0000e-05\nEpoch 50/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7477 - loss: 0.7469\nEpoch 50: val_loss improved from 0.49121 to 0.45022, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7477 - loss: 0.7469 - val_accuracy: 0.8466 - val_loss: 0.4502 - learning_rate: 1.0000e-05\nEpoch 51/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7589 - loss: 0.7085\nEpoch 51: val_loss improved from 0.45022 to 0.42468, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7589 - loss: 0.7085 - val_accuracy: 0.8539 - val_loss: 0.4247 - learning_rate: 1.0000e-05\nEpoch 52/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7827 - loss: 0.6544\nEpoch 52: val_loss improved from 0.42468 to 0.40641, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7827 - loss: 0.6544 - val_accuracy: 0.8591 - val_loss: 0.4064 - learning_rate: 1.0000e-05\nEpoch 53/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7845 - loss: 0.6472\nEpoch 53: val_loss improved from 0.40641 to 0.38506, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7845 - loss: 0.6472 - val_accuracy: 0.8657 - val_loss: 0.3851 - learning_rate: 1.0000e-05\nEpoch 54/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7954 - loss: 0.6152\nEpoch 54: val_loss improved from 0.38506 to 0.37137, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7954 - loss: 0.6152 - val_accuracy: 0.8720 - val_loss: 0.3714 - learning_rate: 1.0000e-05\nEpoch 55/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8054 - loss: 0.5824\nEpoch 55: val_loss improved from 0.37137 to 0.35576, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.8054 - loss: 0.5824 - val_accuracy: 0.8785 - val_loss: 0.3558 - learning_rate: 1.0000e-05\nEpoch 56/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8108 - loss: 0.5830\nEpoch 56: val_loss improved from 0.35576 to 0.34428, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.8108 - loss: 0.5830 - val_accuracy: 0.8830 - val_loss: 0.3443 - learning_rate: 1.0000e-05\nEpoch 57/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8146 - loss: 0.5474\nEpoch 57: val_loss improved from 0.34428 to 0.33435, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.8146 - loss: 0.5474 - val_accuracy: 0.8844 - val_loss: 0.3344 - learning_rate: 1.0000e-05\nEpoch 58/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8273 - loss: 0.5138\nEpoch 58: val_loss improved from 0.33435 to 0.32351, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8272 - loss: 0.5138 - val_accuracy: 0.8890 - val_loss: 0.3235 - learning_rate: 1.0000e-05\nEpoch 59/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8273 - loss: 0.5117\nEpoch 59: val_loss improved from 0.32351 to 0.31742, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 76ms/step - accuracy: 0.8273 - loss: 0.5117 - val_accuracy: 0.8909 - val_loss: 0.3174 - learning_rate: 1.0000e-05\nEpoch 60/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8304 - loss: 0.5001\nEpoch 60: val_loss improved from 0.31742 to 0.30849, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.8304 - loss: 0.5001 - val_accuracy: 0.8933 - val_loss: 0.3085 - learning_rate: 1.0000e-05\nEpoch 61/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8369 - loss: 0.4793\nEpoch 61: val_loss improved from 0.30849 to 0.30366, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.8369 - loss: 0.4793 - val_accuracy: 0.8935 - val_loss: 0.3037 - learning_rate: 1.0000e-05\nEpoch 62/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8420 - loss: 0.4656\nEpoch 62: val_loss improved from 0.30366 to 0.29329, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8420 - loss: 0.4656 - val_accuracy: 0.8990 - val_loss: 0.2933 - learning_rate: 1.0000e-05\nEpoch 63/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8468 - loss: 0.4541\nEpoch 63: val_loss improved from 0.29329 to 0.29004, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8468 - loss: 0.4541 - val_accuracy: 0.8999 - val_loss: 0.2900 - learning_rate: 1.0000e-05\nEpoch 64/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8505 - loss: 0.4439\nEpoch 64: val_loss improved from 0.29004 to 0.28053, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 76ms/step - accuracy: 0.8505 - loss: 0.4439 - val_accuracy: 0.9025 - val_loss: 0.2805 - learning_rate: 1.0000e-05\nEpoch 65/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8583 - loss: 0.4271\nEpoch 65: val_loss improved from 0.28053 to 0.27716, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8583 - loss: 0.4271 - val_accuracy: 0.9034 - val_loss: 0.2772 - learning_rate: 1.0000e-05\nEpoch 66/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8554 - loss: 0.4300\nEpoch 66: val_loss improved from 0.27716 to 0.27241, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8554 - loss: 0.4300 - val_accuracy: 0.9058 - val_loss: 0.2724 - learning_rate: 1.0000e-05\nEpoch 67/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8595 - loss: 0.4172\nEpoch 67: val_loss improved from 0.27241 to 0.27099, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 76ms/step - accuracy: 0.8595 - loss: 0.4172 - val_accuracy: 0.9058 - val_loss: 0.2710 - learning_rate: 1.0000e-05\nEpoch 68/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8619 - loss: 0.4125\nEpoch 68: val_loss improved from 0.27099 to 0.26458, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8619 - loss: 0.4125 - val_accuracy: 0.9084 - val_loss: 0.2646 - learning_rate: 1.0000e-05\nEpoch 69/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8655 - loss: 0.4002\nEpoch 69: val_loss improved from 0.26458 to 0.26376, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8655 - loss: 0.4002 - val_accuracy: 0.9080 - val_loss: 0.2638 - learning_rate: 1.0000e-05\nEpoch 70/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8673 - loss: 0.3939\nEpoch 70: val_loss improved from 0.26376 to 0.25995, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.8673 - loss: 0.3939 - val_accuracy: 0.9106 - val_loss: 0.2600 - learning_rate: 1.0000e-05\nEpoch 71/71\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8679 - loss: 0.3846\nEpoch 71: val_loss improved from 0.25995 to 0.25666, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.8679 - loss: 0.3846 - val_accuracy: 0.9110 - val_loss: 0.2567 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 71.\n소요시간:3846.69초\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 테스트 데이터셋을 이용해 모델을 평가합니다.\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:54:40.706335Z","iopub.execute_input":"2025-06-11T20:54:40.706600Z","iopub.status.idle":"2025-06-11T20:54:45.333853Z","shell.execute_reply.started":"2025-06-11T20:54:40.706579Z","shell.execute_reply":"2025-06-11T20:54:45.333176Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9055 - loss: 0.2709\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[0.27596190571784973, 0.9049000144004822]"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"#### 02-05 전이학습_v2\n- 전이학습시 충분히 학습이 된 것 같지 않아서 epoch수만 변경\n  - 1차 학습 epoch 60(기존 50), 2차 학습 epoch 60(기존 30)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport time\nst = time.time()\n\n# 1. 데이터 로드 및 분할\n(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\nx_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n\n# 2. 데이터 증강 레이어 정의\ndata_augmentation = models.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n], name=\"data_augmentation\")\n\n# --- 모델 구성 ---\n# 3. 기본 모델 로드\nbase_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(75, 75, 3))\nbase_model.trainable = False  # 동결\n\n# 4. Functional API를 사용한 전체 모델 조립\ninputs = layers.Input(shape=(32, 32, 3))\nx = data_augmentation(inputs)\nx = layers.Resizing(75, 75)(x)\nx = preprocess_input(x) # 수동 정규화 대신 여기서 처리\nx = base_model(x, training=False) # training=False 설정이 중요!\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(10, activation='softmax')(x)\n\nmodel = models.Model(inputs, outputs)\n\n# --- 1차 학습 ---\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\ncallbacks_list = [\n    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n    ModelCheckpoint(filepath='cifar10_transfer_best.keras', monitor='val_loss', save_best_only=True, verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)\n]\n\nhistory = model.fit(x_train, y_train,\n                    epochs=60, # 에포크는 조절 가능\n                    validation_data=(x_val, y_val),\n                    callbacks=callbacks_list)\n\n# --- 2차 학습 (미세 조정) ---\nbase_model.trainable = True # 전체 동결 해제\n\n# (선택적) 일부만 동결 해제\n# for layer in base_model.layers[:-20]:\n#     layer.trainable = False\n\nmodel.compile(optimizer=optimizers.Adam(learning_rate=1e-5), # 매우 낮은 학습률\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# initial_epoch를 설정하여 학습 이어가기\nfine_tune_epochs = 60\ntotal_epochs = len(history.epoch) + fine_tune_epochs\n\nfine_tune_history = model.fit(x_train, y_train,\n                              epochs=total_epochs,\n                              initial_epoch=len(history.epoch), # 이전 학습이 끝난 시점부터 시작\n                              validation_data=(x_val, y_val),\n                              callbacks=callbacks_list)\n\n\ned = time.time()\nprint(f'소요시간:{round(ed-st,2)}초')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:27:46.716915Z","iopub.execute_input":"2025-06-13T05:27:46.717229Z","iopub.status.idle":"2025-06-13T07:17:52.720150Z","shell.execute_reply.started":"2025-06-13T05:27:46.717207Z","shell.execute_reply":"2025-06-13T07:17:52.719411Z"}},"outputs":[{"name":"stderr","text":"2025-06-13 05:27:48.330757: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749792468.522674      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749792468.580613      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749792486.582303      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1749792486.583070      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749792503.998657      35 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nI0000 00:00:1749792506.185838     101 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5415 - loss: 1.3129\nEpoch 1: val_loss improved from inf to 0.62695, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 22ms/step - accuracy: 0.5415 - loss: 1.3128 - val_accuracy: 0.7862 - val_loss: 0.6270 - learning_rate: 0.0010\nEpoch 2/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6533 - loss: 1.0036\nEpoch 2: val_loss improved from 0.62695 to 0.59109, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6533 - loss: 1.0035 - val_accuracy: 0.7970 - val_loss: 0.5911 - learning_rate: 0.0010\nEpoch 3/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6765 - loss: 0.9354\nEpoch 3: val_loss improved from 0.59109 to 0.57201, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6765 - loss: 0.9354 - val_accuracy: 0.8000 - val_loss: 0.5720 - learning_rate: 0.0010\nEpoch 4/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6811 - loss: 0.9104\nEpoch 4: val_loss did not improve from 0.57201\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.6811 - loss: 0.9104 - val_accuracy: 0.8001 - val_loss: 0.5734 - learning_rate: 0.0010\nEpoch 5/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6838 - loss: 0.9010\nEpoch 5: val_loss improved from 0.57201 to 0.55286, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6838 - loss: 0.9010 - val_accuracy: 0.8088 - val_loss: 0.5529 - learning_rate: 0.0010\nEpoch 6/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6941 - loss: 0.8852\nEpoch 6: val_loss did not improve from 0.55286\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.6941 - loss: 0.8852 - val_accuracy: 0.8094 - val_loss: 0.5559 - learning_rate: 0.0010\nEpoch 7/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6881 - loss: 0.8822\nEpoch 7: val_loss improved from 0.55286 to 0.54594, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6881 - loss: 0.8822 - val_accuracy: 0.8092 - val_loss: 0.5459 - learning_rate: 0.0010\nEpoch 8/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6972 - loss: 0.8682\nEpoch 8: val_loss improved from 0.54594 to 0.54516, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.6972 - loss: 0.8682 - val_accuracy: 0.8116 - val_loss: 0.5452 - learning_rate: 0.0010\nEpoch 9/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7036 - loss: 0.8549\nEpoch 9: val_loss improved from 0.54516 to 0.54233, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7035 - loss: 0.8549 - val_accuracy: 0.8120 - val_loss: 0.5423 - learning_rate: 0.0010\nEpoch 10/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7013 - loss: 0.8497\nEpoch 10: val_loss did not improve from 0.54233\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.7013 - loss: 0.8497 - val_accuracy: 0.8140 - val_loss: 0.5470 - learning_rate: 0.0010\nEpoch 11/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7075 - loss: 0.8397\nEpoch 11: val_loss improved from 0.54233 to 0.53510, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7075 - loss: 0.8397 - val_accuracy: 0.8132 - val_loss: 0.5351 - learning_rate: 0.0010\nEpoch 12/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7013 - loss: 0.8485\nEpoch 12: val_loss did not improve from 0.53510\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7013 - loss: 0.8485 - val_accuracy: 0.8140 - val_loss: 0.5372 - learning_rate: 0.0010\nEpoch 13/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7067 - loss: 0.8349\nEpoch 13: val_loss did not improve from 0.53510\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7067 - loss: 0.8349 - val_accuracy: 0.8135 - val_loss: 0.5430 - learning_rate: 0.0010\nEpoch 14/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7103 - loss: 0.8289\nEpoch 14: val_loss improved from 0.53510 to 0.52882, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7103 - loss: 0.8289 - val_accuracy: 0.8193 - val_loss: 0.5288 - learning_rate: 0.0010\nEpoch 15/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7108 - loss: 0.8257\nEpoch 15: val_loss did not improve from 0.52882\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7108 - loss: 0.8257 - val_accuracy: 0.8108 - val_loss: 0.5427 - learning_rate: 0.0010\nEpoch 16/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7173 - loss: 0.8147\nEpoch 16: val_loss did not improve from 0.52882\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7173 - loss: 0.8147 - val_accuracy: 0.8177 - val_loss: 0.5296 - learning_rate: 0.0010\nEpoch 17/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7157 - loss: 0.8152\nEpoch 17: val_loss improved from 0.52882 to 0.52476, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7157 - loss: 0.8152 - val_accuracy: 0.8208 - val_loss: 0.5248 - learning_rate: 0.0010\nEpoch 18/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7167 - loss: 0.8099\nEpoch 18: val_loss did not improve from 0.52476\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7167 - loss: 0.8099 - val_accuracy: 0.8162 - val_loss: 0.5441 - learning_rate: 0.0010\nEpoch 19/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7180 - loss: 0.8082\nEpoch 19: val_loss improved from 0.52476 to 0.51612, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7180 - loss: 0.8082 - val_accuracy: 0.8248 - val_loss: 0.5161 - learning_rate: 0.0010\nEpoch 20/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7205 - loss: 0.7954\nEpoch 20: val_loss did not improve from 0.51612\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7205 - loss: 0.7954 - val_accuracy: 0.8187 - val_loss: 0.5216 - learning_rate: 0.0010\nEpoch 21/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7178 - loss: 0.8106\nEpoch 21: val_loss did not improve from 0.51612\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7178 - loss: 0.8106 - val_accuracy: 0.8203 - val_loss: 0.5247 - learning_rate: 0.0010\nEpoch 22/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7186 - loss: 0.7981\nEpoch 22: val_loss did not improve from 0.51612\n\nEpoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7186 - loss: 0.7981 - val_accuracy: 0.8206 - val_loss: 0.5306 - learning_rate: 0.0010\nEpoch 23/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7277 - loss: 0.7854\nEpoch 23: val_loss improved from 0.51612 to 0.50620, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7277 - loss: 0.7853 - val_accuracy: 0.8260 - val_loss: 0.5062 - learning_rate: 2.0000e-04\nEpoch 24/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7360 - loss: 0.7608\nEpoch 24: val_loss improved from 0.50620 to 0.50506, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7360 - loss: 0.7608 - val_accuracy: 0.8269 - val_loss: 0.5051 - learning_rate: 2.0000e-04\nEpoch 25/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7410 - loss: 0.7497\nEpoch 25: val_loss did not improve from 0.50506\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7410 - loss: 0.7497 - val_accuracy: 0.8270 - val_loss: 0.5086 - learning_rate: 2.0000e-04\nEpoch 26/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7413 - loss: 0.7409\nEpoch 26: val_loss did not improve from 0.50506\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7413 - loss: 0.7409 - val_accuracy: 0.8267 - val_loss: 0.5055 - learning_rate: 2.0000e-04\nEpoch 27/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7435 - loss: 0.7422\nEpoch 27: val_loss did not improve from 0.50506\n\nEpoch 27: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.7435 - loss: 0.7422 - val_accuracy: 0.8260 - val_loss: 0.5077 - learning_rate: 2.0000e-04\nEpoch 28/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7467 - loss: 0.7294\nEpoch 28: val_loss did not improve from 0.50506\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7467 - loss: 0.7294 - val_accuracy: 0.8268 - val_loss: 0.5055 - learning_rate: 4.0000e-05\nEpoch 29/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7429 - loss: 0.7493\nEpoch 29: val_loss improved from 0.50506 to 0.50438, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7429 - loss: 0.7493 - val_accuracy: 0.8278 - val_loss: 0.5044 - learning_rate: 4.0000e-05\nEpoch 30/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7489 - loss: 0.7258\nEpoch 30: val_loss did not improve from 0.50438\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7489 - loss: 0.7259 - val_accuracy: 0.8268 - val_loss: 0.5046 - learning_rate: 4.0000e-05\nEpoch 31/60\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7434 - loss: 0.7331\nEpoch 31: val_loss improved from 0.50438 to 0.50418, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7434 - loss: 0.7331 - val_accuracy: 0.8269 - val_loss: 0.5042 - learning_rate: 4.0000e-05\nEpoch 32/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7441 - loss: 0.7331\nEpoch 32: val_loss did not improve from 0.50418\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7441 - loss: 0.7331 - val_accuracy: 0.8273 - val_loss: 0.5057 - learning_rate: 4.0000e-05\nEpoch 33/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7464 - loss: 0.7336\nEpoch 33: val_loss did not improve from 0.50418\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7464 - loss: 0.7336 - val_accuracy: 0.8273 - val_loss: 0.5051 - learning_rate: 4.0000e-05\nEpoch 34/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7455 - loss: 0.7343\nEpoch 34: val_loss improved from 0.50418 to 0.50324, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7455 - loss: 0.7343 - val_accuracy: 0.8284 - val_loss: 0.5032 - learning_rate: 4.0000e-05\nEpoch 35/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7403 - loss: 0.7413\nEpoch 35: val_loss did not improve from 0.50324\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7403 - loss: 0.7413 - val_accuracy: 0.8276 - val_loss: 0.5045 - learning_rate: 4.0000e-05\nEpoch 36/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7537 - loss: 0.7147\nEpoch 36: val_loss did not improve from 0.50324\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7537 - loss: 0.7147 - val_accuracy: 0.8284 - val_loss: 0.5045 - learning_rate: 4.0000e-05\nEpoch 37/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7437 - loss: 0.7325\nEpoch 37: val_loss did not improve from 0.50324\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7437 - loss: 0.7325 - val_accuracy: 0.8270 - val_loss: 0.5033 - learning_rate: 4.0000e-05\nEpoch 38/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7425 - loss: 0.7359\nEpoch 38: val_loss improved from 0.50324 to 0.50306, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7425 - loss: 0.7359 - val_accuracy: 0.8272 - val_loss: 0.5031 - learning_rate: 8.0000e-06\nEpoch 39/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7479 - loss: 0.7177\nEpoch 39: val_loss improved from 0.50306 to 0.50281, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7479 - loss: 0.7177 - val_accuracy: 0.8279 - val_loss: 0.5028 - learning_rate: 8.0000e-06\nEpoch 40/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7498 - loss: 0.7274\nEpoch 40: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7498 - loss: 0.7274 - val_accuracy: 0.8277 - val_loss: 0.5031 - learning_rate: 8.0000e-06\nEpoch 41/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7438 - loss: 0.7246\nEpoch 41: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7438 - loss: 0.7246 - val_accuracy: 0.8276 - val_loss: 0.5032 - learning_rate: 8.0000e-06\nEpoch 42/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7467 - loss: 0.7225\nEpoch 42: val_loss did not improve from 0.50281\n\nEpoch 42: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7467 - loss: 0.7225 - val_accuracy: 0.8280 - val_loss: 0.5029 - learning_rate: 8.0000e-06\nEpoch 43/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7485 - loss: 0.7181\nEpoch 43: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7485 - loss: 0.7181 - val_accuracy: 0.8279 - val_loss: 0.5030 - learning_rate: 1.6000e-06\nEpoch 44/60\n\u001b[1m1247/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7483 - loss: 0.7165\nEpoch 44: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7483 - loss: 0.7165 - val_accuracy: 0.8281 - val_loss: 0.5030 - learning_rate: 1.6000e-06\nEpoch 45/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7452 - loss: 0.7308\nEpoch 45: val_loss did not improve from 0.50281\n\nEpoch 45: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7452 - loss: 0.7308 - val_accuracy: 0.8277 - val_loss: 0.5030 - learning_rate: 1.6000e-06\nEpoch 46/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7461 - loss: 0.7219\nEpoch 46: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7461 - loss: 0.7219 - val_accuracy: 0.8276 - val_loss: 0.5030 - learning_rate: 3.2000e-07\nEpoch 47/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7407 - loss: 0.7401\nEpoch 47: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.7407 - loss: 0.7401 - val_accuracy: 0.8276 - val_loss: 0.5030 - learning_rate: 3.2000e-07\nEpoch 48/60\n\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7454 - loss: 0.7284\nEpoch 48: val_loss did not improve from 0.50281\n\nEpoch 48: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7454 - loss: 0.7284 - val_accuracy: 0.8277 - val_loss: 0.5030 - learning_rate: 3.2000e-07\nEpoch 49/60\n\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7425 - loss: 0.7315\nEpoch 49: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7425 - loss: 0.7315 - val_accuracy: 0.8276 - val_loss: 0.5030 - learning_rate: 6.4000e-08\nEpoch 49: early stopping\nRestoring model weights from the end of the best epoch: 39.\nEpoch 50/109\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749793650.071594      35 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4306 - loss: 2.9134\nEpoch 50: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 74ms/step - accuracy: 0.4307 - loss: 2.9131 - val_accuracy: 0.6540 - val_loss: 1.3327 - learning_rate: 1.0000e-05\nEpoch 51/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5594 - loss: 1.7556\nEpoch 51: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 71ms/step - accuracy: 0.5594 - loss: 1.7555 - val_accuracy: 0.7101 - val_loss: 1.0222 - learning_rate: 1.0000e-05\nEpoch 52/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6170 - loss: 1.3811\nEpoch 52: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 71ms/step - accuracy: 0.6171 - loss: 1.3811 - val_accuracy: 0.7413 - val_loss: 0.8308 - learning_rate: 1.0000e-05\nEpoch 53/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6454 - loss: 1.1707\nEpoch 53: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 71ms/step - accuracy: 0.6454 - loss: 1.1707 - val_accuracy: 0.7721 - val_loss: 0.7120 - learning_rate: 1.0000e-05\nEpoch 54/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6774 - loss: 1.0244\nEpoch 54: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 71ms/step - accuracy: 0.6774 - loss: 1.0244 - val_accuracy: 0.7937 - val_loss: 0.6320 - learning_rate: 1.0000e-05\nEpoch 55/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7002 - loss: 0.9198\nEpoch 55: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 71ms/step - accuracy: 0.7002 - loss: 0.9198 - val_accuracy: 0.8107 - val_loss: 0.5688 - learning_rate: 1.0000e-05\nEpoch 56/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7232 - loss: 0.8401\nEpoch 56: val_loss did not improve from 0.50281\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 71ms/step - accuracy: 0.7232 - loss: 0.8401 - val_accuracy: 0.8230 - val_loss: 0.5204 - learning_rate: 1.0000e-05\nEpoch 57/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7398 - loss: 0.7747\nEpoch 57: val_loss improved from 0.50281 to 0.48676, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.7398 - loss: 0.7747 - val_accuracy: 0.8341 - val_loss: 0.4868 - learning_rate: 1.0000e-05\nEpoch 58/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7539 - loss: 0.7408\nEpoch 58: val_loss improved from 0.48676 to 0.45092, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.7539 - loss: 0.7408 - val_accuracy: 0.8446 - val_loss: 0.4509 - learning_rate: 1.0000e-05\nEpoch 59/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7705 - loss: 0.6889\nEpoch 59: val_loss improved from 0.45092 to 0.42448, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.7705 - loss: 0.6889 - val_accuracy: 0.8513 - val_loss: 0.4245 - learning_rate: 1.0000e-05\nEpoch 60/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7771 - loss: 0.6658\nEpoch 60: val_loss improved from 0.42448 to 0.40443, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.7771 - loss: 0.6658 - val_accuracy: 0.8584 - val_loss: 0.4044 - learning_rate: 1.0000e-05\nEpoch 61/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7830 - loss: 0.6392\nEpoch 61: val_loss improved from 0.40443 to 0.38251, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.7830 - loss: 0.6392 - val_accuracy: 0.8661 - val_loss: 0.3825 - learning_rate: 1.0000e-05\nEpoch 62/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7965 - loss: 0.6103\nEpoch 62: val_loss improved from 0.38251 to 0.37158, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.7965 - loss: 0.6103 - val_accuracy: 0.8715 - val_loss: 0.3716 - learning_rate: 1.0000e-05\nEpoch 63/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8030 - loss: 0.5804\nEpoch 63: val_loss improved from 0.37158 to 0.35190, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8030 - loss: 0.5804 - val_accuracy: 0.8752 - val_loss: 0.3519 - learning_rate: 1.0000e-05\nEpoch 64/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8147 - loss: 0.5591\nEpoch 64: val_loss improved from 0.35190 to 0.34665, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 72ms/step - accuracy: 0.8146 - loss: 0.5591 - val_accuracy: 0.8800 - val_loss: 0.3467 - learning_rate: 1.0000e-05\nEpoch 65/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8180 - loss: 0.5485\nEpoch 65: val_loss improved from 0.34665 to 0.33175, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8180 - loss: 0.5485 - val_accuracy: 0.8831 - val_loss: 0.3318 - learning_rate: 1.0000e-05\nEpoch 66/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8198 - loss: 0.5282\nEpoch 66: val_loss improved from 0.33175 to 0.32259, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 72ms/step - accuracy: 0.8198 - loss: 0.5282 - val_accuracy: 0.8875 - val_loss: 0.3226 - learning_rate: 1.0000e-05\nEpoch 67/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8275 - loss: 0.5138\nEpoch 67: val_loss improved from 0.32259 to 0.31899, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 72ms/step - accuracy: 0.8275 - loss: 0.5138 - val_accuracy: 0.8892 - val_loss: 0.3190 - learning_rate: 1.0000e-05\nEpoch 68/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8329 - loss: 0.4942\nEpoch 68: val_loss improved from 0.31899 to 0.31285, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8329 - loss: 0.4942 - val_accuracy: 0.8920 - val_loss: 0.3128 - learning_rate: 1.0000e-05\nEpoch 69/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8389 - loss: 0.4779\nEpoch 69: val_loss improved from 0.31285 to 0.30132, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8389 - loss: 0.4779 - val_accuracy: 0.8953 - val_loss: 0.3013 - learning_rate: 1.0000e-05\nEpoch 70/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8445 - loss: 0.4625\nEpoch 70: val_loss improved from 0.30132 to 0.29612, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8445 - loss: 0.4625 - val_accuracy: 0.8985 - val_loss: 0.2961 - learning_rate: 1.0000e-05\nEpoch 71/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8493 - loss: 0.4579\nEpoch 71: val_loss improved from 0.29612 to 0.29244, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8493 - loss: 0.4579 - val_accuracy: 0.9000 - val_loss: 0.2924 - learning_rate: 1.0000e-05\nEpoch 72/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8492 - loss: 0.4455\nEpoch 72: val_loss improved from 0.29244 to 0.28829, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8492 - loss: 0.4455 - val_accuracy: 0.9009 - val_loss: 0.2883 - learning_rate: 1.0000e-05\nEpoch 73/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8544 - loss: 0.4329\nEpoch 73: val_loss improved from 0.28829 to 0.28193, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8544 - loss: 0.4329 - val_accuracy: 0.9035 - val_loss: 0.2819 - learning_rate: 1.0000e-05\nEpoch 74/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8562 - loss: 0.4263\nEpoch 74: val_loss improved from 0.28193 to 0.27654, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8562 - loss: 0.4263 - val_accuracy: 0.9048 - val_loss: 0.2765 - learning_rate: 1.0000e-05\nEpoch 75/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8660 - loss: 0.4013\nEpoch 75: val_loss improved from 0.27654 to 0.27210, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8660 - loss: 0.4013 - val_accuracy: 0.9064 - val_loss: 0.2721 - learning_rate: 1.0000e-05\nEpoch 76/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8626 - loss: 0.4099\nEpoch 76: val_loss improved from 0.27210 to 0.26947, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 72ms/step - accuracy: 0.8626 - loss: 0.4099 - val_accuracy: 0.9078 - val_loss: 0.2695 - learning_rate: 1.0000e-05\nEpoch 77/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8688 - loss: 0.3885\nEpoch 77: val_loss did not improve from 0.26947\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 72ms/step - accuracy: 0.8688 - loss: 0.3885 - val_accuracy: 0.9083 - val_loss: 0.2696 - learning_rate: 1.0000e-05\nEpoch 78/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8736 - loss: 0.3878\nEpoch 78: val_loss improved from 0.26947 to 0.26097, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8736 - loss: 0.3878 - val_accuracy: 0.9126 - val_loss: 0.2610 - learning_rate: 1.0000e-05\nEpoch 79/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8719 - loss: 0.3821\nEpoch 79: val_loss did not improve from 0.26097\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 71ms/step - accuracy: 0.8719 - loss: 0.3821 - val_accuracy: 0.9134 - val_loss: 0.2613 - learning_rate: 1.0000e-05\nEpoch 80/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8738 - loss: 0.3737\nEpoch 80: val_loss improved from 0.26097 to 0.25834, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.8738 - loss: 0.3736 - val_accuracy: 0.9129 - val_loss: 0.2583 - learning_rate: 1.0000e-05\nEpoch 81/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8731 - loss: 0.3747\nEpoch 81: val_loss improved from 0.25834 to 0.25607, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8731 - loss: 0.3747 - val_accuracy: 0.9136 - val_loss: 0.2561 - learning_rate: 1.0000e-05\nEpoch 82/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8818 - loss: 0.3419\nEpoch 82: val_loss improved from 0.25607 to 0.25254, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 72ms/step - accuracy: 0.8818 - loss: 0.3419 - val_accuracy: 0.9139 - val_loss: 0.2525 - learning_rate: 1.0000e-05\nEpoch 83/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8820 - loss: 0.3512\nEpoch 83: val_loss improved from 0.25254 to 0.25213, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8820 - loss: 0.3512 - val_accuracy: 0.9166 - val_loss: 0.2521 - learning_rate: 1.0000e-05\nEpoch 84/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8858 - loss: 0.3385\nEpoch 84: val_loss improved from 0.25213 to 0.25010, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8858 - loss: 0.3385 - val_accuracy: 0.9175 - val_loss: 0.2501 - learning_rate: 1.0000e-05\nEpoch 85/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8850 - loss: 0.3317\nEpoch 85: val_loss improved from 0.25010 to 0.24518, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8850 - loss: 0.3317 - val_accuracy: 0.9179 - val_loss: 0.2452 - learning_rate: 1.0000e-05\nEpoch 86/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8878 - loss: 0.3303\nEpoch 86: val_loss improved from 0.24518 to 0.24226, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8878 - loss: 0.3303 - val_accuracy: 0.9180 - val_loss: 0.2423 - learning_rate: 1.0000e-05\nEpoch 87/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8900 - loss: 0.3262\nEpoch 87: val_loss improved from 0.24226 to 0.24089, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8900 - loss: 0.3262 - val_accuracy: 0.9185 - val_loss: 0.2409 - learning_rate: 1.0000e-05\nEpoch 88/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8897 - loss: 0.3251\nEpoch 88: val_loss improved from 0.24089 to 0.23875, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 74ms/step - accuracy: 0.8897 - loss: 0.3251 - val_accuracy: 0.9196 - val_loss: 0.2387 - learning_rate: 1.0000e-05\nEpoch 89/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8984 - loss: 0.3103\nEpoch 89: val_loss improved from 0.23875 to 0.23838, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8984 - loss: 0.3103 - val_accuracy: 0.9211 - val_loss: 0.2384 - learning_rate: 1.0000e-05\nEpoch 90/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8951 - loss: 0.3112\nEpoch 90: val_loss improved from 0.23838 to 0.23827, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8951 - loss: 0.3112 - val_accuracy: 0.9225 - val_loss: 0.2383 - learning_rate: 1.0000e-05\nEpoch 91/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8954 - loss: 0.3091\nEpoch 91: val_loss improved from 0.23827 to 0.23696, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8954 - loss: 0.3091 - val_accuracy: 0.9212 - val_loss: 0.2370 - learning_rate: 1.0000e-05\nEpoch 92/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8958 - loss: 0.3011\nEpoch 92: val_loss improved from 0.23696 to 0.23626, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8958 - loss: 0.3011 - val_accuracy: 0.9221 - val_loss: 0.2363 - learning_rate: 1.0000e-05\nEpoch 93/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8975 - loss: 0.2958\nEpoch 93: val_loss improved from 0.23626 to 0.22986, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8975 - loss: 0.2958 - val_accuracy: 0.9234 - val_loss: 0.2299 - learning_rate: 1.0000e-05\nEpoch 94/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9006 - loss: 0.2871\nEpoch 94: val_loss improved from 0.22986 to 0.22741, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.9006 - loss: 0.2871 - val_accuracy: 0.9246 - val_loss: 0.2274 - learning_rate: 1.0000e-05\nEpoch 95/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9053 - loss: 0.2803\nEpoch 95: val_loss did not improve from 0.22741\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9053 - loss: 0.2803 - val_accuracy: 0.9247 - val_loss: 0.2290 - learning_rate: 1.0000e-05\nEpoch 96/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9038 - loss: 0.2793\nEpoch 96: val_loss did not improve from 0.22741\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9038 - loss: 0.2793 - val_accuracy: 0.9245 - val_loss: 0.2282 - learning_rate: 1.0000e-05\nEpoch 97/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9090 - loss: 0.2690\nEpoch 97: val_loss did not improve from 0.22741\n\nEpoch 97: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9090 - loss: 0.2690 - val_accuracy: 0.9258 - val_loss: 0.2275 - learning_rate: 1.0000e-05\nEpoch 98/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9080 - loss: 0.2716\nEpoch 98: val_loss improved from 0.22741 to 0.22570, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.9080 - loss: 0.2716 - val_accuracy: 0.9264 - val_loss: 0.2257 - learning_rate: 2.0000e-06\nEpoch 99/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9109 - loss: 0.2655\nEpoch 99: val_loss improved from 0.22570 to 0.22354, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.9109 - loss: 0.2655 - val_accuracy: 0.9266 - val_loss: 0.2235 - learning_rate: 2.0000e-06\nEpoch 100/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9112 - loss: 0.2623\nEpoch 100: val_loss did not improve from 0.22354\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9112 - loss: 0.2623 - val_accuracy: 0.9268 - val_loss: 0.2249 - learning_rate: 2.0000e-06\nEpoch 101/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9055 - loss: 0.2744\nEpoch 101: val_loss did not improve from 0.22354\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9055 - loss: 0.2744 - val_accuracy: 0.9276 - val_loss: 0.2238 - learning_rate: 2.0000e-06\nEpoch 102/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9111 - loss: 0.2590\nEpoch 102: val_loss improved from 0.22354 to 0.22315, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 72ms/step - accuracy: 0.9111 - loss: 0.2590 - val_accuracy: 0.9272 - val_loss: 0.2231 - learning_rate: 2.0000e-06\nEpoch 103/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9114 - loss: 0.2624\nEpoch 103: val_loss improved from 0.22315 to 0.22305, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.9114 - loss: 0.2624 - val_accuracy: 0.9273 - val_loss: 0.2231 - learning_rate: 2.0000e-06\nEpoch 104/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9104 - loss: 0.2621\nEpoch 104: val_loss did not improve from 0.22305\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9104 - loss: 0.2621 - val_accuracy: 0.9280 - val_loss: 0.2238 - learning_rate: 2.0000e-06\nEpoch 105/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9161 - loss: 0.2518\nEpoch 105: val_loss improved from 0.22305 to 0.22252, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 72ms/step - accuracy: 0.9161 - loss: 0.2518 - val_accuracy: 0.9285 - val_loss: 0.2225 - learning_rate: 2.0000e-06\nEpoch 106/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9120 - loss: 0.2560\nEpoch 106: val_loss did not improve from 0.22252\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9120 - loss: 0.2560 - val_accuracy: 0.9277 - val_loss: 0.2233 - learning_rate: 2.0000e-06\nEpoch 107/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9124 - loss: 0.2561\nEpoch 107: val_loss did not improve from 0.22252\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9124 - loss: 0.2561 - val_accuracy: 0.9278 - val_loss: 0.2239 - learning_rate: 2.0000e-06\nEpoch 108/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9116 - loss: 0.2524\nEpoch 108: val_loss improved from 0.22252 to 0.22240, saving model to cifar10_transfer_best.keras\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.9116 - loss: 0.2524 - val_accuracy: 0.9275 - val_loss: 0.2224 - learning_rate: 2.0000e-06\nEpoch 109/109\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9133 - loss: 0.2614\nEpoch 109: val_loss did not improve from 0.22240\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - accuracy: 0.9133 - loss: 0.2614 - val_accuracy: 0.9284 - val_loss: 0.2245 - learning_rate: 2.0000e-06\nRestoring model weights from the end of the best epoch: 108.\n소요시간:6591.75초\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 테스트 데이터셋을 이용해 모델을 평가합니다.\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T07:31:19.491180Z","iopub.execute_input":"2025-06-13T07:31:19.491671Z","iopub.status.idle":"2025-06-13T07:31:24.264805Z","shell.execute_reply.started":"2025-06-13T07:31:19.491646Z","shell.execute_reply":"2025-06-13T07:31:24.264108Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9249 - loss: 0.2297\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[0.23493364453315735, 0.9228000044822693]"},"metadata":{}}],"execution_count":3}]}